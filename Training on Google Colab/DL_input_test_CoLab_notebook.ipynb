{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_input_test_CoLab_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akmazad/deepBrain/blob/master/Training%20on%20Google%20Colab/DL_input_test_CoLab_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF5nbjNPqDKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "152cbf19-0b1b-4c91-b67c-d6e916c97991"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bQOwm_eUKo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5593
        },
        "outputId": "942d9fe9-1b7c-44a8-ac1d-bd0a03be16e6"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as tdata\n",
        "import torch.nn.functional as tfunc\n",
        "import torch.optim as topti\n",
        "import logging\n",
        "import os\n",
        "import torch.cuda\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch.tensor\n",
        "\n",
        "class config():\n",
        "  def __init__(self):\n",
        "    self.name = \"deepbrainStaticConvnet\"\n",
        "    self.DataDir = \"gdrive/My Drive/chr_5_files_TF_signal_filtered/\"\n",
        "#     self.TrainingDataFile = \"tempTrain5_trainingData_TF_filtered_chr5_value.npy\"\n",
        "#     self.TrainingLabelFile = \"tempTrain5_trainingData_TF_filtered_chr5_label_all.npy\"\n",
        "#     self.TestingDataFile = \"tempTrain5_validationData_TF_filtered_chr5_value.npy\"\n",
        "#     self.TestingLabelFile = \"tempTrain5_validationData_TF_filtered_chr5_label_all.npy\"\n",
        "\n",
        "    self.TrainingDataFile = \"H3K27ac_rnaSeq.Pos.tfSpecific_trainingData_TF_filtered_chr5_value.npy\"\n",
        "    self.TrainingLabelFile = \"H3K27ac_rnaSeq.Pos.tfSpecific_trainingData_TF_filtered_chr5_label_all.npy\"\n",
        "    self.TestingDataFile = \"H3K27ac_rnaSeq.Pos.tfSpecific_validationData_TF_filtered_chr5_value.npy\"\n",
        "    self.TestingLabelFile = \"H3K27ac_rnaSeq.Pos.tfSpecific_validationData_TF_filtered_chr5_label_all.npy\"\n",
        "    \n",
        "    self.w_lr = 1e-2\n",
        "    self.w_lr_min = 8e-7\n",
        "    self.w_momentum = 0.9\n",
        "    self.w_weight_decay = 5e-7\n",
        "    self.w_grad_clip = 5\n",
        "    self.print_freq = 50\n",
        "    self.init_channels = 16\n",
        "    self.layers = 8\n",
        "    self.BATCH_SIZE = 128\n",
        "    self.seed = 0\n",
        "    self.workers = 4 \n",
        "    self.alpha_lr = 3e-4\n",
        "    self.alpha_weight_decay = 1e-4\n",
        "    self.world_size = -1\n",
        "    self.rank = 0\n",
        "    self.dist_url = 'env://'\n",
        "    self.dist_backend = 'nccl'\n",
        "    self.gpu = None\n",
        "    self.multiprocessing_distributed = True\n",
        "    self.nEpochs = 15\n",
        "    self.start_epoch = 0\n",
        "\n",
        "    # architecture-related parameters\n",
        "    # 3 conv-layers, 1 fully connected layers (See DeepSEA paper)\n",
        "    self.CONV1_INPUT_CHANNELS = 4\n",
        "    self.CONV1_OUTPUT_CHANNELS = 320\n",
        "    self.CONV2_OUTPUT_CHANNELS = 480\n",
        "    self.CONV3_OUTPUT_CHANNELS = 960\n",
        "    self.KERNEL_SIZE = 8\n",
        "    self.POOLING_TH = 4\n",
        "    self.DROPOUT_l1 = 0.2\n",
        "    self.DROPOUT_l2 = 0.2\n",
        "    self.DROPOUT_l3 = 0.5\n",
        "    self.NUM_OUTPUTS = 131\n",
        "    self.SEQ_LEN = 1000\n",
        "\n",
        "    \n",
        "best_acc1 = 0\n",
        "\n",
        "# model zone\n",
        "class BuildModel(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(BuildModel, self).__init__()\n",
        "\n",
        "        # Create and initialise weights and biases for the layers.\n",
        "        # regularization parameters could be introduced later (see deepsea/deepsea_model.py)\n",
        "        self.conv_layer1 = nn.Conv1d(args.CONV1_INPUT_CHANNELS, args.CONV1_OUTPUT_CHANNELS, args.KERNEL_SIZE)\n",
        "        self.conv_layer2 = nn.Conv1d(args.CONV1_OUTPUT_CHANNELS, args.CONV2_OUTPUT_CHANNELS, args.KERNEL_SIZE)\n",
        "        self.conv_layer3 = nn.Conv1d(args.CONV2_OUTPUT_CHANNELS, args.CONV3_OUTPUT_CHANNELS, args.KERNEL_SIZE)\n",
        "\n",
        "        nChannel = math.floor((args.SEQ_LEN - (args.KERNEL_SIZE - 1)) / args.POOLING_TH)\n",
        "        nChannel = math.floor((nChannel - (args.KERNEL_SIZE - 1)) / args.POOLING_TH)\n",
        "        nChannel = math.floor((nChannel - (args.KERNEL_SIZE - 1)) / args.POOLING_TH)\n",
        "        self.fc1 = nn.Linear(args.CONV3_OUTPUT_CHANNELS * nChannel, args.NUM_OUTPUTS)\n",
        "\n",
        "    def forward(self, x, args):\n",
        "        # Create the forward pass through the network.\n",
        "        x = self.conv_layer1(x)\n",
        "        x = tfunc.leaky_relu(x, 0.01)\n",
        "        x = tfunc.max_pool1d(x, args.POOLING_TH)  # downsample by half (i.e. if parameter=4, then by quarter)\n",
        "        # x = tfunc.batch_norm(x, torch.zeros(args.CONV1_OUTPUT_CHANNELS), torch.ones(args.CONV1_OUTPUT_CHANNELS))\n",
        "        x = tfunc.dropout(x, args.DROPOUT_l1)\n",
        "\n",
        "        x = self.conv_layer2(x)\n",
        "        x = tfunc.leaky_relu(x, 0.01)\n",
        "        x = tfunc.max_pool1d(x, args.POOLING_TH)\n",
        "        # x = tfunc.batch_norm(x, torch.zeros(args.CONV2_OUTPUT_CHANNELS), torch.ones(args.CONV2_OUTPUT_CHANNELS))\n",
        "        x = tfunc.dropout(x, args.DROPOUT_l2)\n",
        "\n",
        "        x = self.conv_layer3(x)\n",
        "        x = tfunc.leaky_relu(x, 0.1)\n",
        "        x = tfunc.max_pool1d(x, args.POOLING_TH)\n",
        "        # x = tfunc.batch_norm(x, torch.zeros(args.CONV3_OUTPUT_CHANNELS), torch.ones(args.CONV3_OUTPUT_CHANNELS))\n",
        "        x = tfunc.dropout(x, args.DROPOUT_l3)\n",
        "\n",
        "        # for the fully connected layer\n",
        "        x = x.view(x.shape[0], -1)  # Flatten tensor.\n",
        "        x = self.fc1(x)\n",
        "        x = tfunc.leaky_relu(x, 0.01)\n",
        "        #         x = tfunc.dropout(x, 0.2)\n",
        "        # x = tfunc.batch_norm(x, torch.zeros(K).cuda(), torch.ones(K).cuda())\n",
        "        x = torch.sigmoid(x)\n",
        "        # x = F.log_softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class DeepSEA(nn.Module):\n",
        "    def __init__(self, sequence_length, n_genomic_features):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        sequence_length : int\n",
        "        n_genomic_features : int\n",
        "        \"\"\"\n",
        "        super(DeepSEA, self).__init__()\n",
        "        conv_kernel_size = 8\n",
        "        pool_kernel_size = 4\n",
        "\n",
        "        self.conv_net = nn.Sequential(\n",
        "            nn.Conv1d(4, 320, kernel_size=conv_kernel_size),\n",
        "            # nn.ReLU(inplace=True),\n",
        "            nn.Threshold(0, 1e-06),\n",
        "\n",
        "            nn.MaxPool1d(\n",
        "                kernel_size=pool_kernel_size, stride=pool_kernel_size),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Conv1d(320, 480, kernel_size=conv_kernel_size),\n",
        "            # nn.ReLU(inplace=True),\n",
        "            nn.Threshold(0, 1e-06),\n",
        "            nn.MaxPool1d(\n",
        "                kernel_size=pool_kernel_size, stride=pool_kernel_size),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Conv1d(480, 960, kernel_size=conv_kernel_size),\n",
        "            # nn.ReLU(inplace=True),\n",
        "            nn.Threshold(0, 1e-06),\n",
        "            nn.Dropout(p=0.5))\n",
        "\n",
        "        reduce_by = conv_kernel_size - 1\n",
        "        pool_kernel_size = float(pool_kernel_size)\n",
        "        self.n_channels = int(\n",
        "            np.floor(\n",
        "                (np.floor(\n",
        "                    (sequence_length - reduce_by) / pool_kernel_size)\n",
        "                 - reduce_by) / pool_kernel_size)\n",
        "            - reduce_by)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(960 * self.n_channels, n_genomic_features),\n",
        "            # nn.ReLU(inplace=True),\n",
        "            nn.Threshold(0, 1e-06),\n",
        "            nn.Linear(n_genomic_features, n_genomic_features),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward propagation of a batch.\n",
        "        \"\"\"\n",
        "        out = self.conv_net(x)\n",
        "        reshape_out = out.view(out.size(0), 960 * self.n_channels)\n",
        "        predict = self.classifier(reshape_out)\n",
        "        return predict\n",
        "\n",
        "\n",
        "class DeeperDeepSEA(nn.Module):\n",
        "    \"\"\"\n",
        "    A deeper DeepSEA model architecture.\n",
        "    Parameters\n",
        "    ----------\n",
        "    sequence_length : int\n",
        "        The length of the sequences on which the model trains and and makes\n",
        "        predictions.\n",
        "    n_targets : int\n",
        "        The number of targets (classes) to predict.\n",
        "    Attributes\n",
        "    ----------\n",
        "    conv_net : torch.nn.Sequential\n",
        "        The convolutional neural network component of the model.\n",
        "    classifier : torch.nn.Sequential\n",
        "        The linear classifier and sigmoid transformation components of the\n",
        "        model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sequence_length, n_targets):\n",
        "        super(DeeperDeepSEA, self).__init__()\n",
        "        conv_kernel_size = 8\n",
        "        pool_kernel_size = 4\n",
        "\n",
        "        self.conv_net = nn.Sequential(\n",
        "            nn.Conv1d(4, 320, kernel_size=conv_kernel_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(320, 320, kernel_size=conv_kernel_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(\n",
        "                kernel_size=pool_kernel_size, stride=pool_kernel_size),\n",
        "            nn.BatchNorm1d(320),\n",
        "\n",
        "            nn.Conv1d(320, 480, kernel_size=conv_kernel_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(480, 480, kernel_size=conv_kernel_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool1d(\n",
        "                kernel_size=pool_kernel_size, stride=pool_kernel_size),\n",
        "            nn.BatchNorm1d(480),\n",
        "            nn.Dropout(p=0.2),\n",
        "\n",
        "            nn.Conv1d(480, 960, kernel_size=conv_kernel_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(960, 960, kernel_size=conv_kernel_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(960),\n",
        "            nn.Dropout(p=0.2))\n",
        "\n",
        "        reduce_by = 2 * (conv_kernel_size - 1)\n",
        "        pool_kernel_size = float(pool_kernel_size)\n",
        "        self._n_channels = int(\n",
        "            np.floor(\n",
        "                (np.floor(\n",
        "                    (sequence_length - reduce_by) / pool_kernel_size)\n",
        "                 - reduce_by) / pool_kernel_size)\n",
        "            - reduce_by)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(960 * self._n_channels, n_targets),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(n_targets),\n",
        "            nn.Linear(n_targets, n_targets),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward propagation of a batch.\n",
        "        \"\"\"\n",
        "        out = self.conv_net(x)\n",
        "        reshape_out = out.view(out.size(0), 960 * self._n_channels)\n",
        "        predict = self.classifier(reshape_out)\n",
        "        return predict\n",
        "\n",
        "class ReCodeAlphabet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ReCodeAlphabet, self).__init__()\n",
        "        #\n",
        "    def forward(self, input):\n",
        "        # Swap ACGT to AGCT\n",
        "        # array has shape (N, 4, 1, 1000)\n",
        "        # pytorch doesn't support full indexing at the moment, at some point this should work: [:,:,torch.LongTensor([0,2,1,3])]\n",
        "        input_reordered = [input[:,i,...] for i in [0,2,1,3]]\n",
        "        input = torch.stack(input_reordered, dim=1)\n",
        "        # slightly faster but ugly:\n",
        "        #input = edit_tensor_in_numpy(input, lambda x: x[:,[0,2,1,3], ...])\n",
        "        return input\n",
        "\n",
        "\n",
        "class LambdaBase(nn.Sequential):\n",
        "    def __init__(self, fn, *args):\n",
        "        super(LambdaBase, self).__init__(*args)\n",
        "        self.lambda_func = fn\n",
        "        #\n",
        "    def forward_prepare(self, input):\n",
        "        output = []\n",
        "        for module in self._modules.values():\n",
        "            output.append(module(input))\n",
        "        return output if output else input\n",
        "\n",
        "\n",
        "class Lambda(LambdaBase):\n",
        "    def forward(self, input):\n",
        "        return self.lambda_func(self.forward_prepare(input))\n",
        "\n",
        "\n",
        "def get_model(load_weights = True):\n",
        "    deepsea_cpu = nn.Sequential( # Sequential,\n",
        "        nn.Conv2d(4,320,(1, 8),(1, 1)),\n",
        "        nn.Threshold(0, 1e-06),\n",
        "        nn.MaxPool2d((1, 4),(1, 4)),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Conv2d(320,480,(1, 8),(1, 1)),\n",
        "        nn.Threshold(0, 1e-06),\n",
        "        nn.MaxPool2d((1, 4),(1, 4)),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Conv2d(480,960,(1, 8),(1, 1)),\n",
        "        nn.Threshold(0, 1e-06),\n",
        "        nn.Dropout(0.5),\n",
        "        Lambda(lambda x: x.view(x.size(0),-1)), # Reshape,\n",
        "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(50880,925)), # Linear,\n",
        "        nn.Threshold(0, 1e-06),\n",
        "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(925,919)), # Linear,\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "    if load_weights:\n",
        "        deepsea_cpu.load_state_dict(torch.load('model_files/deepsea_cpu.pth'))\n",
        "    return nn.Sequential(ReCodeAlphabet(), deepsea_cpu)\n",
        "\n",
        "\n",
        "class LoadDataset(tdata.Dataset):\n",
        "    def __init__(self, args, dataPath, dataFile, labelFile):\n",
        "        # Load data from files.\n",
        "        # self.inputs = np.memmap(dataPath + dataFile, mode=\"r\").reshape(-1, args.CONV1_INPUT_CHANNELS, args.SEQ_LEN)\n",
        "        # self.labels = np.memmap(dataPath + labelFile, mode=\"r\").reshape(-1, args.NUM_OUTPUTS)\n",
        "\n",
        "        self.inputs = np.load(dataPath + dataFile)\n",
        "        self.labels = np.load(dataPath + labelFile)\n",
        "\n",
        "        self.length = len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Return a single input/label pair from the dataset.\n",
        "        inputSample = np.array(self.inputs[index], dtype=np.float32)\n",
        "        labelSample = np.array(self.labels[index], dtype=np.float32)\n",
        "        sample = (inputSample, labelSample)\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def getCustomAccuracy(predicted, target, args):\n",
        "    # predicted = torch.round(torch.sigmoid(predicted))\n",
        "    # predicted = torch.round(predicted)\n",
        "    n_digits = 3\n",
        "    _predicted = torch.round(predicted * 10 ** n_digits) / (10 ** n_digits)\n",
        "    __predicted = torch.round(_predicted)\n",
        "\n",
        "    N = predicted.size(0) * args.NUM_OUTPUTS\n",
        "\n",
        "    truePred = torch.sum(torch.eq(__predicted, target)).item()\n",
        "    acc_val = truePred / N\n",
        "\n",
        "    # print(torch.sum(torch.eq(target, torch.ones(target.shape))).item())\n",
        "    # print(torch.sum(torch.eq(predicted, torch.ones(target.shape))).item())\n",
        "    return acc_val\n",
        "\n",
        "\n",
        "def getCustomAccuracy2(predicted, target, args):\n",
        "    # predicted = torch.round(torch.sigmoid(predicted))\n",
        "    # predicted = torch.round(predicted)\n",
        "    n_digits = 3    # to have something like 0.499 = 0.5\n",
        "    _predicted = torch.round(predicted * 10 ** n_digits) / (10 ** n_digits)\n",
        "    __predicted = torch.round(_predicted)\n",
        "\n",
        "\n",
        "\n",
        "    N = predicted.size(0)\n",
        "    custom_accuracy = np.zeros(args.NUM_OUTPUTS, dtype=np.float)\n",
        "    for i in range(args.NUM_OUTPUTS):\n",
        "        truePred = torch.sum(torch.eq(__predicted[:, i], target[:, i])).item()\n",
        "        custom_accuracy[i] = truePred/N\n",
        "\n",
        "    return np.median(custom_accuracy[:2]), np.median(custom_accuracy[2]), np.median(custom_accuracy[3:])\n",
        "\n",
        "\n",
        "def getCustomAccuracy3(predicted, target, args):\n",
        "    preds = []\n",
        "    targets = []\n",
        "    for i in range(10):\n",
        "        o = F.log_softmax(torch.autograd.Variable(predicted), dim=1)\n",
        "        t = torch.autograd.Variable(target)\n",
        "\n",
        "        _, pred = torch.max(o, dim=1)\n",
        "        preds.append(pred.data)\n",
        "        targets.append(t.data)\n",
        "\n",
        "    preds = torch.cat(preds)\n",
        "    targets = torch.cat(targets)\n",
        "\n",
        "\n",
        "def getAUCscore(predicted, target, args, logger):\n",
        "    # n_digits = 3\n",
        "    # _predicted = torch.round(predicted * 10**n_digits) / (10**n_digits)\n",
        "    # __predicted = torch.round(_predicted)\n",
        "\n",
        "    # _predicted = torch.round(predicted).detach()\n",
        "    __predicted = predicted.detach()\n",
        "    _target = target.detach()\n",
        "\n",
        "    aucs = np.zeros(args.NUM_OUTPUTS, dtype=np.float)\n",
        "    for i in range(args.NUM_OUTPUTS):\n",
        "        try:\n",
        "            auc = roc_auc_score(_target.cpu().numpy()[:, i], __predicted.cpu().numpy()[:, i], average='weighted')\n",
        "            aucs[i] = auc\n",
        "        except ValueError as e:\n",
        "            pass\n",
        "            # logger.info(\"NA (No positive (i.e. signal) in Test region)\")\n",
        "\n",
        "    # print('Medican AUCs: Accetylation marks: %.3f, RNA-seq: %.3f, TFs: %.3f' % (np.median(aucs[:2]), np.median(aucs[2]), np.median(aucs[3:])))\n",
        "\n",
        "    return np.median(aucs[:2]), np.median(aucs[2]), np.median(aucs[3:])\n",
        "\n",
        "\n",
        "def get_logger(file_path):\n",
        "    \"\"\" Make python logger \"\"\"\n",
        "    # [!] Since tensorboardX use default logger (e.g. logging.info()), we should use custom logger\n",
        "    logger = logging.getLogger('db2')\n",
        "    log_format = '%(asctime)s | %(message)s'\n",
        "    formatter = logging.Formatter(log_format, datefmt='%m/%d %I:%M:%S %p')\n",
        "    file_handler = logging.FileHandler(file_path)\n",
        "    file_handler.setFormatter(formatter)\n",
        "    stream_handler = logging.StreamHandler()\n",
        "    stream_handler.setFormatter(formatter)\n",
        "\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(stream_handler)\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    return logger\n",
        "\n",
        "\n",
        "def find_perc_uncertainty(output, low, high):\n",
        "    output = output.detach().cpu().numpy()\n",
        "    return np.sum(np.logical_and(output>=low, output<=high))/output.size    # returns the proportion of tensor elements are within the range\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch, args, logger, device):\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    # perc_uncertainty = 0.0\n",
        "\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "      \n",
        "        input = input.cuda(device, non_blocking=True)\n",
        "        target = target.cuda(device, non_blocking=True)\n",
        "        \n",
        "        # compute output\n",
        "        # output = model(input, args)\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target.squeeze(1))\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        # acc = getCustomAccuracy(output, target, args)\n",
        "        perc_uncertainty = find_perc_uncertainty(output, 0.4, 0.6)\n",
        "        custom_accuracy = getCustomAccuracy2(output, target, args)\n",
        "        # tAccuracy = getCustomAccuracy3(output, target, args)\n",
        "        aucs = getAUCscore(output, target, args, logger)\n",
        "\n",
        "        # compute gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # add l1 Sparsity\n",
        "        l1 = 0\n",
        "        for p in model.parameters():\n",
        "            l1 = l1 + p.abs().sum()\n",
        "        loss = loss + 1e-8 * l1\n",
        "\n",
        "        # do SGD step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % args.print_freq == 0 or i == len(train_loader) - 1:\n",
        "          logger.info(\"TRAINING: Epoch: %d, Batch: %d/%d, Loss: %.3f, perc_uncertainty: %.3f, custom[ACC:%.3f, rnaSEQ:%.3f, TFs:%.3f], roc[ACC:%.3f, rnSEQ:%.3f, TFs:%.3f]\" \n",
        "                      % (epoch + 1, i, len(train_loader) - 1,\n",
        "                         loss, perc_uncertainty, custom_accuracy[0], \n",
        "                         custom_accuracy[1], custom_accuracy[2], \n",
        "                         aucs[0], aucs[1], aucs[2]))\n",
        "\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, args, logger, device):\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "    total_ACC, total_RNA, total_TFs = 0, 0, 0\n",
        "    perc_uncertainty = 0.0\n",
        "\n",
        "    # losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            \n",
        "            input = input.cuda(device, non_blocking=True)\n",
        "            target = target.cuda(device, non_blocking=True)\n",
        "        \n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "            # losses[i] = loss\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            # acc = getCustomAccuracy(output, target, args)\n",
        "            p = find_perc_uncertainty(output, 0.4, 0.6)\n",
        "            custom_accuracy = getCustomAccuracy2(output, target, args)\n",
        "            aucs = getAUCscore(output, target, args, logger)\n",
        "\n",
        "            total_ACC += np.median(aucs[0])\n",
        "            total_RNA += np.median(aucs[1])\n",
        "            total_TFs += np.median(aucs[2])\n",
        "\n",
        "            if i % args.print_freq == 0 or i == len(val_loader) - 1:\n",
        "                # progress._print(i)\n",
        "                # logger.info(\"batch: %d, loss: %.3f; valid accuracy: custom_accuracy_metric: %.3f, ACC marks: %.3f, RNA-seq: %.3f, TFs: %.3f\" % (i+1, loss, acc, aucs[0], aucs[1], aucs[2]))\n",
        "                logger.info(\"VALIDATION: Batch: %d/%d, Loss: %.3f, perc_uncertainty: %.3f, custom[ACC:%.3f, rnaSEQ:%.3f, TFs:%.3f], roc[ACC: %.3f, rnSEQ: %.3f, TFs:%.3f]\" % (i, len(val_loader)-1, loss, perc_uncertainty, custom_accuracy[0], custom_accuracy[1], custom_accuracy[2], aucs[0], aucs[1], aucs[2]))\n",
        "            perc_uncertainty += p\n",
        "\n",
        "        # logger.info(' * Acc@1 {top1.avg:.3f}'.format(top1=acc))\n",
        "        logger.info(\"percentage of uncertainty in validation prediction: {}\".format(perc_uncertainty / len(val_loader)))\n",
        "\n",
        "    total_ACC /= len(val_loader)\n",
        "    total_RNA /= len(val_loader)\n",
        "    total_TFs /= len(val_loader)\n",
        "\n",
        "    return np.median([total_ACC, total_RNA, total_TFs])\n",
        "    # return np.median(losses), np.median([total_ACC, total_RNA, total_TFs])\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, args, lr_scheduler):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    # lr = args.w_lr * (0.1 ** (epoch // 30))   # option 1\n",
        "    lr_scheduler.step()     # option 2\n",
        "    lr = lr_scheduler.get_lr()[0]\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Training settings\n",
        "    args = config()\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(args.seed)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    print(device)\n",
        "\n",
        "    DataPath = args.DataDir\n",
        "    logger = get_logger(os.path.join(os.path.join(DataPath, args.name, 'staticConvNet'), \"{}.log\".format(args.name)))\n",
        "\n",
        "    trainDataset = LoadDataset(args, dataPath=DataPath, dataFile=args.TrainingDataFile,\n",
        "                               labelFile=args.TrainingLabelFile)\n",
        "    # define sampler\n",
        "    train_sampler = torch.utils.data.sampler.RandomSampler(trainDataset)\n",
        "\n",
        "    trainLoader = tdata.DataLoader(trainDataset, batch_size=args.BATCH_SIZE, shuffle=(train_sampler is None),\n",
        "                                   num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
        "\n",
        "    # Load the testing dataset, and create a data loader to generate a batch. CHANGE THIS ONCE TESTING DATASET IS READY\n",
        "    valDataset = LoadDataset(args, dataPath=DataPath, dataFile=args.TestingDataFile, labelFile=args.TestingLabelFile)\n",
        "    valLoader = tdata.DataLoader(dataset=valDataset, batch_size=args.BATCH_SIZE, shuffle=False,\n",
        "                                 num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "    # build the model and criterion\n",
        "    # model = BuildModel(args).to(device)\n",
        "    # model = DeepSEA(args.SEQ_LEN, args.NUM_OUTPUTS).to(device)\n",
        "    model = DeeperDeepSEA(args.SEQ_LEN, args.NUM_OUTPUTS).to(device)\n",
        "    # model = get_model(load_weights=False)\n",
        "\n",
        "    # Add a sigmoid activation function to the output.  Use a binary cross entropy\n",
        "    criterion = nn.BCELoss().to(device)\n",
        "    # criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # optimiser = topti.Adam(model.parameters(), lr=args.w_lr)  # Minimise the loss using the Adam algorithm.\n",
        "#     optimiser = torch.optim.Adam(model.parameters(), args.w_lr, betas=(0.5, 0.999),\n",
        "#                                    weight_decay=args.w_weight_decay)\n",
        "    # print(model.parameters())\n",
        "    optimiser = torch.optim.SGD(model.parameters(), args.w_lr, momentum=args.w_momentum, weight_decay=args.w_weight_decay)\n",
        "\n",
        "    # model = DeepSEA(args.SEQ_LEN, args.NUM_OUTPUTS).to(device)\n",
        "    # criterion = nn.BCELoss()\n",
        "    # optimiser = (torch.optim.SGD, {\"lr\": args.w_lr, \"weight_decay\": 1e-6, \"momentum\": 0.9})\n",
        "\n",
        "\n",
        "\n",
        "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimiser, args.nEpochs, eta_min=args.w_lr_min)\n",
        "    # lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimiser, args.nEpochs, eta_min=0)\n",
        "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, 'min')\n",
        "\n",
        "    best_acc1 = 0.0\n",
        "    for epoch in range(args.start_epoch, args.nEpochs):\n",
        "\n",
        "        adjust_learning_rate(optimiser, epoch, args, lr_scheduler)\n",
        "\n",
        "        # train for one epoch\n",
        "        train(trainLoader, model, criterion, optimiser, epoch, args, logger, device)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        acc1 = validate(valLoader, model, criterion, args, logger, device)\n",
        "\n",
        "        # scheduler.step(acc1[1])\n",
        "\n",
        "        # remember best acc@1 and save checkpoint\n",
        "        is_best = acc1 > best_acc1\n",
        "        best_acc1 = max(acc1, best_acc1)\n",
        "\n",
        "    # if (args.save_model):\n",
        "    #     torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
        "    torch.save(model.state_dict(), \"deepBrain2_cnn.pt\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "05/31 02:48:50 AM | TRAINING: Epoch: 1, Batch: 0/11962, Loss: 0.705, perc_uncertainty: 0.788, custom[ACC:0.555, rnaSEQ:0.461, TFs:0.500], roc[ACC:0.536, rnSEQ:0.503, TFs:0.445]\n",
            "05/31 02:49:13 AM | TRAINING: Epoch: 1, Batch: 50/11962, Loss: 0.694, perc_uncertainty: 0.803, custom[ACC:0.609, rnaSEQ:0.516, TFs:0.547], roc[ACC:0.630, rnSEQ:0.577, TFs:0.514]\n",
            "05/31 02:49:36 AM | TRAINING: Epoch: 1, Batch: 100/11962, Loss: 0.677, perc_uncertainty: 0.871, custom[ACC:0.602, rnaSEQ:0.516, TFs:0.578], roc[ACC:0.765, rnSEQ:0.585, TFs:0.531]\n",
            "05/31 02:50:01 AM | TRAINING: Epoch: 1, Batch: 150/11962, Loss: 0.664, perc_uncertainty: 0.909, custom[ACC:0.660, rnaSEQ:0.445, TFs:0.648], roc[ACC:0.757, rnSEQ:0.495, TFs:0.616]\n",
            "05/31 02:50:25 AM | TRAINING: Epoch: 1, Batch: 200/11962, Loss: 0.650, perc_uncertainty: 0.917, custom[ACC:0.711, rnaSEQ:0.508, TFs:0.719], roc[ACC:0.764, rnSEQ:0.546, TFs:0.595]\n",
            "05/31 02:50:48 AM | TRAINING: Epoch: 1, Batch: 250/11962, Loss: 0.637, perc_uncertainty: 0.917, custom[ACC:0.711, rnaSEQ:0.430, TFs:0.773], roc[ACC:0.732, rnSEQ:0.481, TFs:0.552]\n",
            "05/31 02:51:12 AM | TRAINING: Epoch: 1, Batch: 300/11962, Loss: 0.621, perc_uncertainty: 0.905, custom[ACC:0.734, rnaSEQ:0.508, TFs:0.871], roc[ACC:0.749, rnSEQ:0.575, TFs:0.562]\n",
            "05/31 02:51:37 AM | TRAINING: Epoch: 1, Batch: 350/11962, Loss: 0.601, perc_uncertainty: 0.873, custom[ACC:0.797, rnaSEQ:0.461, TFs:0.906], roc[ACC:0.801, rnSEQ:0.529, TFs:0.577]\n",
            "05/31 02:52:01 AM | TRAINING: Epoch: 1, Batch: 400/11962, Loss: 0.581, perc_uncertainty: 0.799, custom[ACC:0.770, rnaSEQ:0.477, TFs:0.945], roc[ACC:0.587, rnSEQ:0.516, TFs:0.487]\n",
            "05/31 02:52:24 AM | TRAINING: Epoch: 1, Batch: 450/11962, Loss: 0.554, perc_uncertainty: 0.668, custom[ACC:0.824, rnaSEQ:0.562, TFs:0.953], roc[ACC:0.806, rnSEQ:0.589, TFs:0.623]\n",
            "05/31 02:52:49 AM | TRAINING: Epoch: 1, Batch: 500/11962, Loss: 0.522, perc_uncertainty: 0.464, custom[ACC:0.832, rnaSEQ:0.570, TFs:0.969], roc[ACC:0.829, rnSEQ:0.568, TFs:0.559]\n",
            "05/31 02:53:12 AM | TRAINING: Epoch: 1, Batch: 550/11962, Loss: 0.493, perc_uncertainty: 0.249, custom[ACC:0.805, rnaSEQ:0.656, TFs:0.969], roc[ACC:0.702, rnSEQ:0.585, TFs:0.597]\n",
            "05/31 02:53:37 AM | TRAINING: Epoch: 1, Batch: 600/11962, Loss: 0.451, perc_uncertainty: 0.111, custom[ACC:0.812, rnaSEQ:0.609, TFs:0.984], roc[ACC:0.746, rnSEQ:0.556, TFs:0.505]\n",
            "05/31 02:54:00 AM | TRAINING: Epoch: 1, Batch: 650/11962, Loss: 0.416, perc_uncertainty: 0.058, custom[ACC:0.820, rnaSEQ:0.758, TFs:0.969], roc[ACC:0.735, rnSEQ:0.474, TFs:0.629]\n",
            "05/31 02:54:25 AM | TRAINING: Epoch: 1, Batch: 700/11962, Loss: 0.369, perc_uncertainty: 0.025, custom[ACC:0.832, rnaSEQ:0.656, TFs:0.977], roc[ACC:0.664, rnSEQ:0.578, TFs:0.593]\n",
            "05/31 02:54:48 AM | TRAINING: Epoch: 1, Batch: 750/11962, Loss: 0.336, perc_uncertainty: 0.014, custom[ACC:0.855, rnaSEQ:0.625, TFs:0.977], roc[ACC:0.752, rnSEQ:0.603, TFs:0.577]\n",
            "05/31 02:55:12 AM | TRAINING: Epoch: 1, Batch: 800/11962, Loss: 0.297, perc_uncertainty: 0.009, custom[ACC:0.852, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.757, rnSEQ:0.556, TFs:0.580]\n",
            "05/31 02:55:36 AM | TRAINING: Epoch: 1, Batch: 850/11962, Loss: 0.261, perc_uncertainty: 0.007, custom[ACC:0.863, rnaSEQ:0.641, TFs:0.984], roc[ACC:0.727, rnSEQ:0.651, TFs:0.627]\n",
            "05/31 02:56:00 AM | TRAINING: Epoch: 1, Batch: 900/11962, Loss: 0.245, perc_uncertainty: 0.003, custom[ACC:0.891, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.823, rnSEQ:0.498, TFs:0.685]\n",
            "05/31 02:56:24 AM | TRAINING: Epoch: 1, Batch: 950/11962, Loss: 0.206, perc_uncertainty: 0.004, custom[ACC:0.867, rnaSEQ:0.711, TFs:0.984], roc[ACC:0.795, rnSEQ:0.642, TFs:0.477]\n",
            "05/31 02:56:48 AM | TRAINING: Epoch: 1, Batch: 1000/11962, Loss: 0.199, perc_uncertainty: 0.003, custom[ACC:0.816, rnaSEQ:0.766, TFs:0.984], roc[ACC:0.738, rnSEQ:0.574, TFs:0.622]\n",
            "05/31 02:57:12 AM | TRAINING: Epoch: 1, Batch: 1050/11962, Loss: 0.190, perc_uncertainty: 0.002, custom[ACC:0.852, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.769, rnSEQ:0.589, TFs:0.671]\n",
            "05/31 02:57:35 AM | TRAINING: Epoch: 1, Batch: 1100/11962, Loss: 0.171, perc_uncertainty: 0.002, custom[ACC:0.859, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.786, rnSEQ:0.558, TFs:0.616]\n",
            "05/31 02:57:59 AM | TRAINING: Epoch: 1, Batch: 1150/11962, Loss: 0.174, perc_uncertainty: 0.002, custom[ACC:0.879, rnaSEQ:0.656, TFs:0.977], roc[ACC:0.832, rnSEQ:0.600, TFs:0.735]\n",
            "05/31 02:58:23 AM | TRAINING: Epoch: 1, Batch: 1200/11962, Loss: 0.163, perc_uncertainty: 0.003, custom[ACC:0.898, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.764, rnSEQ:0.554, TFs:0.665]\n",
            "05/31 02:58:48 AM | TRAINING: Epoch: 1, Batch: 1250/11962, Loss: 0.170, perc_uncertainty: 0.002, custom[ACC:0.848, rnaSEQ:0.648, TFs:0.977], roc[ACC:0.798, rnSEQ:0.595, TFs:0.565]\n",
            "05/31 02:59:11 AM | TRAINING: Epoch: 1, Batch: 1300/11962, Loss: 0.154, perc_uncertainty: 0.003, custom[ACC:0.832, rnaSEQ:0.641, TFs:0.977], roc[ACC:0.685, rnSEQ:0.555, TFs:0.545]\n",
            "05/31 02:59:36 AM | TRAINING: Epoch: 1, Batch: 1350/11962, Loss: 0.145, perc_uncertainty: 0.004, custom[ACC:0.871, rnaSEQ:0.711, TFs:0.977], roc[ACC:0.816, rnSEQ:0.684, TFs:0.684]\n",
            "05/31 02:59:59 AM | TRAINING: Epoch: 1, Batch: 1400/11962, Loss: 0.131, perc_uncertainty: 0.002, custom[ACC:0.906, rnaSEQ:0.641, TFs:0.984], roc[ACC:0.809, rnSEQ:0.509, TFs:0.506]\n",
            "05/31 03:00:23 AM | TRAINING: Epoch: 1, Batch: 1450/11962, Loss: 0.143, perc_uncertainty: 0.002, custom[ACC:0.906, rnaSEQ:0.648, TFs:0.977], roc[ACC:0.836, rnSEQ:0.532, TFs:0.665]\n",
            "05/31 03:00:48 AM | TRAINING: Epoch: 1, Batch: 1500/11962, Loss: 0.139, perc_uncertainty: 0.003, custom[ACC:0.875, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.772, rnSEQ:0.611, TFs:0.728]\n",
            "05/31 03:01:11 AM | TRAINING: Epoch: 1, Batch: 1550/11962, Loss: 0.128, perc_uncertainty: 0.002, custom[ACC:0.914, rnaSEQ:0.734, TFs:0.984], roc[ACC:0.753, rnSEQ:0.540, TFs:0.651]\n",
            "05/31 03:01:37 AM | TRAINING: Epoch: 1, Batch: 1600/11962, Loss: 0.136, perc_uncertainty: 0.002, custom[ACC:0.895, rnaSEQ:0.578, TFs:0.977], roc[ACC:0.744, rnSEQ:0.646, TFs:0.655]\n",
            "05/31 03:02:00 AM | TRAINING: Epoch: 1, Batch: 1650/11962, Loss: 0.153, perc_uncertainty: 0.002, custom[ACC:0.789, rnaSEQ:0.633, TFs:0.977], roc[ACC:0.717, rnSEQ:0.530, TFs:0.586]\n",
            "05/31 03:02:24 AM | TRAINING: Epoch: 1, Batch: 1700/11962, Loss: 0.122, perc_uncertainty: 0.003, custom[ACC:0.875, rnaSEQ:0.617, TFs:0.984], roc[ACC:0.754, rnSEQ:0.573, TFs:0.532]\n",
            "05/31 03:02:48 AM | TRAINING: Epoch: 1, Batch: 1750/11962, Loss: 0.124, perc_uncertainty: 0.002, custom[ACC:0.883, rnaSEQ:0.742, TFs:0.984], roc[ACC:0.848, rnSEQ:0.457, TFs:0.644]\n",
            "05/31 03:03:11 AM | TRAINING: Epoch: 1, Batch: 1800/11962, Loss: 0.139, perc_uncertainty: 0.004, custom[ACC:0.875, rnaSEQ:0.727, TFs:0.977], roc[ACC:0.823, rnSEQ:0.530, TFs:0.632]\n",
            "05/31 03:03:35 AM | TRAINING: Epoch: 1, Batch: 1850/11962, Loss: 0.150, perc_uncertainty: 0.003, custom[ACC:0.859, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.731, rnSEQ:0.474, TFs:0.675]\n",
            "05/31 03:03:59 AM | TRAINING: Epoch: 1, Batch: 1900/11962, Loss: 0.122, perc_uncertainty: 0.003, custom[ACC:0.863, rnaSEQ:0.641, TFs:0.984], roc[ACC:0.760, rnSEQ:0.626, TFs:0.567]\n",
            "05/31 03:04:23 AM | TRAINING: Epoch: 1, Batch: 1950/11962, Loss: 0.126, perc_uncertainty: 0.003, custom[ACC:0.887, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.695, rnSEQ:0.536, TFs:0.582]\n",
            "05/31 03:04:48 AM | TRAINING: Epoch: 1, Batch: 2000/11962, Loss: 0.139, perc_uncertainty: 0.003, custom[ACC:0.871, rnaSEQ:0.656, TFs:0.977], roc[ACC:0.813, rnSEQ:0.640, TFs:0.706]\n",
            "05/31 03:05:11 AM | TRAINING: Epoch: 1, Batch: 2050/11962, Loss: 0.115, perc_uncertainty: 0.003, custom[ACC:0.898, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.759, rnSEQ:0.689, TFs:0.646]\n",
            "05/31 03:05:35 AM | TRAINING: Epoch: 1, Batch: 2100/11962, Loss: 0.135, perc_uncertainty: 0.003, custom[ACC:0.875, rnaSEQ:0.656, TFs:0.977], roc[ACC:0.835, rnSEQ:0.649, TFs:0.673]\n",
            "05/31 03:05:59 AM | TRAINING: Epoch: 1, Batch: 2150/11962, Loss: 0.127, perc_uncertainty: 0.003, custom[ACC:0.875, rnaSEQ:0.594, TFs:0.977], roc[ACC:0.843, rnSEQ:0.531, TFs:0.635]\n",
            "05/31 03:06:23 AM | TRAINING: Epoch: 1, Batch: 2200/11962, Loss: 0.122, perc_uncertainty: 0.003, custom[ACC:0.883, rnaSEQ:0.602, TFs:0.977], roc[ACC:0.801, rnSEQ:0.541, TFs:0.641]\n",
            "05/31 03:06:48 AM | TRAINING: Epoch: 1, Batch: 2250/11962, Loss: 0.130, perc_uncertainty: 0.003, custom[ACC:0.887, rnaSEQ:0.609, TFs:0.977], roc[ACC:0.844, rnSEQ:0.599, TFs:0.708]\n",
            "05/31 03:07:12 AM | TRAINING: Epoch: 1, Batch: 2300/11962, Loss: 0.124, perc_uncertainty: 0.003, custom[ACC:0.910, rnaSEQ:0.625, TFs:0.984], roc[ACC:0.816, rnSEQ:0.606, TFs:0.635]\n",
            "05/31 03:07:35 AM | TRAINING: Epoch: 1, Batch: 2350/11962, Loss: 0.113, perc_uncertainty: 0.002, custom[ACC:0.859, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.811, rnSEQ:0.598, TFs:0.642]\n",
            "05/31 03:08:00 AM | TRAINING: Epoch: 1, Batch: 2400/11962, Loss: 0.130, perc_uncertainty: 0.003, custom[ACC:0.867, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.792, rnSEQ:0.549, TFs:0.617]\n",
            "05/31 03:08:23 AM | TRAINING: Epoch: 1, Batch: 2450/11962, Loss: 0.112, perc_uncertainty: 0.003, custom[ACC:0.895, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.718, rnSEQ:0.445, TFs:0.519]\n",
            "05/31 03:08:48 AM | TRAINING: Epoch: 1, Batch: 2500/11962, Loss: 0.118, perc_uncertainty: 0.003, custom[ACC:0.898, rnaSEQ:0.711, TFs:0.984], roc[ACC:0.834, rnSEQ:0.672, TFs:0.601]\n",
            "05/31 03:09:11 AM | TRAINING: Epoch: 1, Batch: 2550/11962, Loss: 0.116, perc_uncertainty: 0.002, custom[ACC:0.867, rnaSEQ:0.727, TFs:0.984], roc[ACC:0.756, rnSEQ:0.594, TFs:0.627]\n",
            "05/31 03:09:36 AM | TRAINING: Epoch: 1, Batch: 2600/11962, Loss: 0.118, perc_uncertainty: 0.003, custom[ACC:0.867, rnaSEQ:0.695, TFs:0.984], roc[ACC:0.814, rnSEQ:0.535, TFs:0.638]\n",
            "05/31 03:09:59 AM | TRAINING: Epoch: 1, Batch: 2650/11962, Loss: 0.118, perc_uncertainty: 0.003, custom[ACC:0.891, rnaSEQ:0.609, TFs:0.984], roc[ACC:0.841, rnSEQ:0.662, TFs:0.621]\n",
            "05/31 03:10:23 AM | TRAINING: Epoch: 1, Batch: 2700/11962, Loss: 0.141, perc_uncertainty: 0.003, custom[ACC:0.891, rnaSEQ:0.633, TFs:0.977], roc[ACC:0.791, rnSEQ:0.467, TFs:0.668]\n",
            "05/31 03:10:47 AM | TRAINING: Epoch: 1, Batch: 2750/11962, Loss: 0.138, perc_uncertainty: 0.003, custom[ACC:0.918, rnaSEQ:0.617, TFs:0.969], roc[ACC:0.852, rnSEQ:0.589, TFs:0.739]\n",
            "05/31 03:11:11 AM | TRAINING: Epoch: 1, Batch: 2800/11962, Loss: 0.129, perc_uncertainty: 0.004, custom[ACC:0.832, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.789, rnSEQ:0.549, TFs:0.636]\n",
            "05/31 03:11:35 AM | TRAINING: Epoch: 1, Batch: 2850/11962, Loss: 0.100, perc_uncertainty: 0.003, custom[ACC:0.875, rnaSEQ:0.664, TFs:0.992], roc[ACC:0.726, rnSEQ:0.491, TFs:0.565]\n",
            "05/31 03:11:59 AM | TRAINING: Epoch: 1, Batch: 2900/11962, Loss: 0.134, perc_uncertainty: 0.003, custom[ACC:0.824, rnaSEQ:0.719, TFs:0.977], roc[ACC:0.748, rnSEQ:0.617, TFs:0.660]\n",
            "05/31 03:12:23 AM | TRAINING: Epoch: 1, Batch: 2950/11962, Loss: 0.136, perc_uncertainty: 0.003, custom[ACC:0.805, rnaSEQ:0.656, TFs:0.984], roc[ACC:0.722, rnSEQ:0.674, TFs:0.608]\n",
            "05/31 03:12:46 AM | TRAINING: Epoch: 1, Batch: 3000/11962, Loss: 0.114, perc_uncertainty: 0.003, custom[ACC:0.859, rnaSEQ:0.625, TFs:0.984], roc[ACC:0.787, rnSEQ:0.499, TFs:0.613]\n",
            "05/31 03:13:10 AM | TRAINING: Epoch: 1, Batch: 3050/11962, Loss: 0.124, perc_uncertainty: 0.004, custom[ACC:0.891, rnaSEQ:0.633, TFs:0.980], roc[ACC:0.881, rnSEQ:0.460, TFs:0.546]\n",
            "05/31 03:13:33 AM | TRAINING: Epoch: 1, Batch: 3100/11962, Loss: 0.108, perc_uncertainty: 0.003, custom[ACC:0.855, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.821, rnSEQ:0.578, TFs:0.540]\n",
            "05/31 03:13:58 AM | TRAINING: Epoch: 1, Batch: 3150/11962, Loss: 0.129, perc_uncertainty: 0.003, custom[ACC:0.906, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.804, rnSEQ:0.589, TFs:0.718]\n",
            "05/31 03:14:21 AM | TRAINING: Epoch: 1, Batch: 3200/11962, Loss: 0.118, perc_uncertainty: 0.003, custom[ACC:0.879, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.712, rnSEQ:0.449, TFs:0.574]\n",
            "05/31 03:14:46 AM | TRAINING: Epoch: 1, Batch: 3250/11962, Loss: 0.134, perc_uncertainty: 0.003, custom[ACC:0.883, rnaSEQ:0.766, TFs:0.977], roc[ACC:0.837, rnSEQ:0.572, TFs:0.640]\n",
            "05/31 03:15:09 AM | TRAINING: Epoch: 1, Batch: 3300/11962, Loss: 0.117, perc_uncertainty: 0.004, custom[ACC:0.891, rnaSEQ:0.719, TFs:0.984], roc[ACC:0.769, rnSEQ:0.607, TFs:0.656]\n",
            "05/31 03:15:34 AM | TRAINING: Epoch: 1, Batch: 3350/11962, Loss: 0.120, perc_uncertainty: 0.004, custom[ACC:0.875, rnaSEQ:0.688, TFs:0.984], roc[ACC:0.810, rnSEQ:0.532, TFs:0.660]\n",
            "05/31 03:15:57 AM | TRAINING: Epoch: 1, Batch: 3400/11962, Loss: 0.125, perc_uncertainty: 0.002, custom[ACC:0.867, rnaSEQ:0.703, TFs:0.980], roc[ACC:0.713, rnSEQ:0.437, TFs:0.610]\n",
            "05/31 03:16:21 AM | TRAINING: Epoch: 1, Batch: 3450/11962, Loss: 0.152, perc_uncertainty: 0.004, custom[ACC:0.828, rnaSEQ:0.734, TFs:0.969], roc[ACC:0.760, rnSEQ:0.557, TFs:0.715]\n",
            "05/31 03:16:44 AM | TRAINING: Epoch: 1, Batch: 3500/11962, Loss: 0.114, perc_uncertainty: 0.003, custom[ACC:0.855, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.655, rnSEQ:0.498, TFs:0.576]\n",
            "05/31 03:17:09 AM | TRAINING: Epoch: 1, Batch: 3550/11962, Loss: 0.113, perc_uncertainty: 0.004, custom[ACC:0.891, rnaSEQ:0.648, TFs:0.984], roc[ACC:0.758, rnSEQ:0.536, TFs:0.629]\n",
            "05/31 03:17:32 AM | TRAINING: Epoch: 1, Batch: 3600/11962, Loss: 0.113, perc_uncertainty: 0.005, custom[ACC:0.895, rnaSEQ:0.617, TFs:0.984], roc[ACC:0.823, rnSEQ:0.593, TFs:0.621]\n",
            "05/31 03:17:57 AM | TRAINING: Epoch: 1, Batch: 3650/11962, Loss: 0.112, perc_uncertainty: 0.003, custom[ACC:0.863, rnaSEQ:0.711, TFs:0.984], roc[ACC:0.755, rnSEQ:0.584, TFs:0.570]\n",
            "05/31 03:18:20 AM | TRAINING: Epoch: 1, Batch: 3700/11962, Loss: 0.113, perc_uncertainty: 0.004, custom[ACC:0.891, rnaSEQ:0.711, TFs:0.984], roc[ACC:0.734, rnSEQ:0.606, TFs:0.674]\n",
            "05/31 03:18:44 AM | TRAINING: Epoch: 1, Batch: 3750/11962, Loss: 0.115, perc_uncertainty: 0.004, custom[ACC:0.852, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.847, rnSEQ:0.532, TFs:0.631]\n",
            "05/31 03:19:08 AM | TRAINING: Epoch: 1, Batch: 3800/11962, Loss: 0.115, perc_uncertainty: 0.004, custom[ACC:0.859, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.777, rnSEQ:0.566, TFs:0.778]\n",
            "05/31 03:19:32 AM | TRAINING: Epoch: 1, Batch: 3850/11962, Loss: 0.113, perc_uncertainty: 0.004, custom[ACC:0.879, rnaSEQ:0.625, TFs:0.984], roc[ACC:0.835, rnSEQ:0.616, TFs:0.737]\n",
            "05/31 03:19:56 AM | TRAINING: Epoch: 1, Batch: 3900/11962, Loss: 0.116, perc_uncertainty: 0.004, custom[ACC:0.848, rnaSEQ:0.727, TFs:0.984], roc[ACC:0.815, rnSEQ:0.477, TFs:0.638]\n",
            "05/31 03:20:19 AM | TRAINING: Epoch: 1, Batch: 3950/11962, Loss: 0.118, perc_uncertainty: 0.004, custom[ACC:0.887, rnaSEQ:0.625, TFs:0.984], roc[ACC:0.751, rnSEQ:0.442, TFs:0.642]\n",
            "05/31 03:20:42 AM | TRAINING: Epoch: 1, Batch: 4000/11962, Loss: 0.121, perc_uncertainty: 0.004, custom[ACC:0.875, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.872, rnSEQ:0.563, TFs:0.720]\n",
            "05/31 03:21:07 AM | TRAINING: Epoch: 1, Batch: 4050/11962, Loss: 0.120, perc_uncertainty: 0.003, custom[ACC:0.883, rnaSEQ:0.711, TFs:0.980], roc[ACC:0.840, rnSEQ:0.701, TFs:0.679]\n",
            "05/31 03:21:30 AM | TRAINING: Epoch: 1, Batch: 4100/11962, Loss: 0.106, perc_uncertainty: 0.004, custom[ACC:0.891, rnaSEQ:0.648, TFs:0.984], roc[ACC:0.812, rnSEQ:0.572, TFs:0.684]\n",
            "05/31 03:21:55 AM | TRAINING: Epoch: 1, Batch: 4150/11962, Loss: 0.134, perc_uncertainty: 0.004, custom[ACC:0.895, rnaSEQ:0.625, TFs:0.973], roc[ACC:0.829, rnSEQ:0.626, TFs:0.796]\n",
            "05/31 03:22:19 AM | TRAINING: Epoch: 1, Batch: 4200/11962, Loss: 0.132, perc_uncertainty: 0.004, custom[ACC:0.879, rnaSEQ:0.609, TFs:0.977], roc[ACC:0.800, rnSEQ:0.532, TFs:0.659]\n",
            "05/31 03:22:43 AM | TRAINING: Epoch: 1, Batch: 4250/11962, Loss: 0.110, perc_uncertainty: 0.004, custom[ACC:0.867, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.825, rnSEQ:0.549, TFs:0.715]\n",
            "05/31 03:23:07 AM | TRAINING: Epoch: 1, Batch: 4300/11962, Loss: 0.114, perc_uncertainty: 0.003, custom[ACC:0.902, rnaSEQ:0.711, TFs:0.984], roc[ACC:0.818, rnSEQ:0.532, TFs:0.635]\n",
            "05/31 03:23:30 AM | TRAINING: Epoch: 1, Batch: 4350/11962, Loss: 0.140, perc_uncertainty: 0.004, custom[ACC:0.840, rnaSEQ:0.602, TFs:0.969], roc[ACC:0.763, rnSEQ:0.607, TFs:0.791]\n",
            "05/31 03:23:55 AM | TRAINING: Epoch: 1, Batch: 4400/11962, Loss: 0.107, perc_uncertainty: 0.004, custom[ACC:0.883, rnaSEQ:0.641, TFs:0.984], roc[ACC:0.746, rnSEQ:0.571, TFs:0.669]\n",
            "05/31 03:24:18 AM | TRAINING: Epoch: 1, Batch: 4450/11962, Loss: 0.114, perc_uncertainty: 0.005, custom[ACC:0.902, rnaSEQ:0.648, TFs:0.984], roc[ACC:0.767, rnSEQ:0.567, TFs:0.540]\n",
            "05/31 03:24:43 AM | TRAINING: Epoch: 1, Batch: 4500/11962, Loss: 0.125, perc_uncertainty: 0.004, custom[ACC:0.836, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.740, rnSEQ:0.617, TFs:0.712]\n",
            "05/31 03:25:07 AM | TRAINING: Epoch: 1, Batch: 4550/11962, Loss: 0.142, perc_uncertainty: 0.005, custom[ACC:0.836, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.732, rnSEQ:0.544, TFs:0.767]\n",
            "05/31 03:25:32 AM | TRAINING: Epoch: 1, Batch: 4600/11962, Loss: 0.126, perc_uncertainty: 0.004, custom[ACC:0.879, rnaSEQ:0.656, TFs:0.977], roc[ACC:0.789, rnSEQ:0.496, TFs:0.616]\n",
            "05/31 03:25:57 AM | TRAINING: Epoch: 1, Batch: 4650/11962, Loss: 0.117, perc_uncertainty: 0.004, custom[ACC:0.859, rnaSEQ:0.672, TFs:0.977], roc[ACC:0.832, rnSEQ:0.534, TFs:0.739]\n",
            "05/31 03:26:20 AM | TRAINING: Epoch: 1, Batch: 4700/11962, Loss: 0.110, perc_uncertainty: 0.004, custom[ACC:0.871, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.819, rnSEQ:0.528, TFs:0.752]\n",
            "05/31 03:26:45 AM | TRAINING: Epoch: 1, Batch: 4750/11962, Loss: 0.129, perc_uncertainty: 0.005, custom[ACC:0.859, rnaSEQ:0.719, TFs:0.977], roc[ACC:0.783, rnSEQ:0.591, TFs:0.645]\n",
            "05/31 03:27:08 AM | TRAINING: Epoch: 1, Batch: 4800/11962, Loss: 0.131, perc_uncertainty: 0.006, custom[ACC:0.887, rnaSEQ:0.664, TFs:0.977], roc[ACC:0.807, rnSEQ:0.608, TFs:0.749]\n",
            "05/31 03:27:33 AM | TRAINING: Epoch: 1, Batch: 4850/11962, Loss: 0.122, perc_uncertainty: 0.003, custom[ACC:0.891, rnaSEQ:0.758, TFs:0.977], roc[ACC:0.761, rnSEQ:0.487, TFs:0.676]\n",
            "05/31 03:27:56 AM | TRAINING: Epoch: 1, Batch: 4900/11962, Loss: 0.123, perc_uncertainty: 0.004, custom[ACC:0.902, rnaSEQ:0.586, TFs:0.980], roc[ACC:0.900, rnSEQ:0.630, TFs:0.700]\n",
            "05/31 03:28:20 AM | TRAINING: Epoch: 1, Batch: 4950/11962, Loss: 0.128, perc_uncertainty: 0.004, custom[ACC:0.875, rnaSEQ:0.672, TFs:0.977], roc[ACC:0.818, rnSEQ:0.613, TFs:0.762]\n",
            "05/31 03:28:44 AM | TRAINING: Epoch: 1, Batch: 5000/11962, Loss: 0.116, perc_uncertainty: 0.004, custom[ACC:0.867, rnaSEQ:0.672, TFs:0.984], roc[ACC:0.796, rnSEQ:0.553, TFs:0.595]\n",
            "05/31 03:29:08 AM | TRAINING: Epoch: 1, Batch: 5050/11962, Loss: 0.134, perc_uncertainty: 0.004, custom[ACC:0.922, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.875, rnSEQ:0.540, TFs:0.684]\n",
            "05/31 03:29:32 AM | TRAINING: Epoch: 1, Batch: 5100/11962, Loss: 0.113, perc_uncertainty: 0.004, custom[ACC:0.918, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.838, rnSEQ:0.582, TFs:0.827]\n",
            "05/31 03:29:56 AM | TRAINING: Epoch: 1, Batch: 5150/11962, Loss: 0.122, perc_uncertainty: 0.005, custom[ACC:0.840, rnaSEQ:0.742, TFs:0.977], roc[ACC:0.765, rnSEQ:0.617, TFs:0.690]\n",
            "05/31 03:30:20 AM | TRAINING: Epoch: 1, Batch: 5200/11962, Loss: 0.143, perc_uncertainty: 0.005, custom[ACC:0.852, rnaSEQ:0.594, TFs:0.969], roc[ACC:0.777, rnSEQ:0.648, TFs:0.808]\n",
            "05/31 03:30:43 AM | TRAINING: Epoch: 1, Batch: 5250/11962, Loss: 0.123, perc_uncertainty: 0.004, custom[ACC:0.836, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.804, rnSEQ:0.529, TFs:0.754]\n",
            "05/31 03:31:08 AM | TRAINING: Epoch: 1, Batch: 5300/11962, Loss: 0.132, perc_uncertainty: 0.005, custom[ACC:0.887, rnaSEQ:0.609, TFs:0.977], roc[ACC:0.871, rnSEQ:0.602, TFs:0.802]\n",
            "05/31 03:31:31 AM | TRAINING: Epoch: 1, Batch: 5350/11962, Loss: 0.117, perc_uncertainty: 0.006, custom[ACC:0.871, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.840, rnSEQ:0.497, TFs:0.795]\n",
            "05/31 03:31:56 AM | TRAINING: Epoch: 1, Batch: 5400/11962, Loss: 0.118, perc_uncertainty: 0.005, custom[ACC:0.859, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.767, rnSEQ:0.557, TFs:0.739]\n",
            "05/31 03:32:20 AM | TRAINING: Epoch: 1, Batch: 5450/11962, Loss: 0.120, perc_uncertainty: 0.004, custom[ACC:0.840, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.779, rnSEQ:0.610, TFs:0.634]\n",
            "05/31 03:32:44 AM | TRAINING: Epoch: 1, Batch: 5500/11962, Loss: 0.100, perc_uncertainty: 0.004, custom[ACC:0.891, rnaSEQ:0.648, TFs:0.992], roc[ACC:0.808, rnSEQ:0.623, TFs:0.628]\n",
            "05/31 03:33:08 AM | TRAINING: Epoch: 1, Batch: 5550/11962, Loss: 0.107, perc_uncertainty: 0.004, custom[ACC:0.883, rnaSEQ:0.656, TFs:0.984], roc[ACC:0.791, rnSEQ:0.579, TFs:0.709]\n",
            "05/31 03:33:32 AM | TRAINING: Epoch: 1, Batch: 5600/11962, Loss: 0.131, perc_uncertainty: 0.004, custom[ACC:0.895, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.842, rnSEQ:0.620, TFs:0.673]\n",
            "05/31 03:33:56 AM | TRAINING: Epoch: 1, Batch: 5650/11962, Loss: 0.131, perc_uncertainty: 0.004, custom[ACC:0.852, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.820, rnSEQ:0.653, TFs:0.768]\n",
            "05/31 03:34:20 AM | TRAINING: Epoch: 1, Batch: 5700/11962, Loss: 0.127, perc_uncertainty: 0.004, custom[ACC:0.855, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.850, rnSEQ:0.640, TFs:0.693]\n",
            "05/31 03:34:43 AM | TRAINING: Epoch: 1, Batch: 5750/11962, Loss: 0.130, perc_uncertainty: 0.004, custom[ACC:0.859, rnaSEQ:0.617, TFs:0.977], roc[ACC:0.830, rnSEQ:0.586, TFs:0.756]\n",
            "05/31 03:35:08 AM | TRAINING: Epoch: 1, Batch: 5800/11962, Loss: 0.137, perc_uncertainty: 0.003, custom[ACC:0.875, rnaSEQ:0.664, TFs:0.977], roc[ACC:0.815, rnSEQ:0.617, TFs:0.689]\n",
            "05/31 03:35:31 AM | TRAINING: Epoch: 1, Batch: 5850/11962, Loss: 0.124, perc_uncertainty: 0.005, custom[ACC:0.883, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.801, rnSEQ:0.448, TFs:0.768]\n",
            "05/31 03:35:55 AM | TRAINING: Epoch: 1, Batch: 5900/11962, Loss: 0.127, perc_uncertainty: 0.005, custom[ACC:0.895, rnaSEQ:0.617, TFs:0.977], roc[ACC:0.793, rnSEQ:0.546, TFs:0.756]\n",
            "05/31 03:36:19 AM | TRAINING: Epoch: 1, Batch: 5950/11962, Loss: 0.142, perc_uncertainty: 0.004, custom[ACC:0.855, rnaSEQ:0.742, TFs:0.977], roc[ACC:0.866, rnSEQ:0.628, TFs:0.723]\n",
            "05/31 03:36:42 AM | TRAINING: Epoch: 1, Batch: 6000/11962, Loss: 0.122, perc_uncertainty: 0.005, custom[ACC:0.852, rnaSEQ:0.805, TFs:0.984], roc[ACC:0.801, rnSEQ:0.514, TFs:0.704]\n",
            "05/31 03:37:07 AM | TRAINING: Epoch: 1, Batch: 6050/11962, Loss: 0.153, perc_uncertainty: 0.005, custom[ACC:0.840, rnaSEQ:0.672, TFs:0.969], roc[ACC:0.816, rnSEQ:0.615, TFs:0.764]\n",
            "05/31 03:37:30 AM | TRAINING: Epoch: 1, Batch: 6100/11962, Loss: 0.120, perc_uncertainty: 0.005, custom[ACC:0.918, rnaSEQ:0.625, TFs:0.984], roc[ACC:0.908, rnSEQ:0.603, TFs:0.722]\n",
            "05/31 03:37:55 AM | TRAINING: Epoch: 1, Batch: 6150/11962, Loss: 0.110, perc_uncertainty: 0.004, custom[ACC:0.855, rnaSEQ:0.633, TFs:0.984], roc[ACC:0.814, rnSEQ:0.615, TFs:0.622]\n",
            "05/31 03:38:19 AM | TRAINING: Epoch: 1, Batch: 6200/11962, Loss: 0.124, perc_uncertainty: 0.004, custom[ACC:0.879, rnaSEQ:0.656, TFs:0.980], roc[ACC:0.782, rnSEQ:0.573, TFs:0.713]\n",
            "05/31 03:38:44 AM | TRAINING: Epoch: 1, Batch: 6250/11962, Loss: 0.105, perc_uncertainty: 0.004, custom[ACC:0.871, rnaSEQ:0.648, TFs:0.984], roc[ACC:0.709, rnSEQ:0.497, TFs:0.677]\n",
            "05/31 03:39:07 AM | TRAINING: Epoch: 1, Batch: 6300/11962, Loss: 0.128, perc_uncertainty: 0.004, custom[ACC:0.887, rnaSEQ:0.672, TFs:0.977], roc[ACC:0.828, rnSEQ:0.655, TFs:0.727]\n",
            "05/31 03:39:31 AM | TRAINING: Epoch: 1, Batch: 6350/11962, Loss: 0.123, perc_uncertainty: 0.005, custom[ACC:0.848, rnaSEQ:0.773, TFs:0.977], roc[ACC:0.793, rnSEQ:0.545, TFs:0.716]\n",
            "05/31 03:39:54 AM | TRAINING: Epoch: 1, Batch: 6400/11962, Loss: 0.128, perc_uncertainty: 0.004, custom[ACC:0.883, rnaSEQ:0.727, TFs:0.977], roc[ACC:0.784, rnSEQ:0.601, TFs:0.690]\n",
            "05/31 03:40:18 AM | TRAINING: Epoch: 1, Batch: 6450/11962, Loss: 0.128, perc_uncertainty: 0.004, custom[ACC:0.867, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.693, rnSEQ:0.482, TFs:0.739]\n",
            "05/31 03:40:42 AM | TRAINING: Epoch: 1, Batch: 6500/11962, Loss: 0.115, perc_uncertainty: 0.005, custom[ACC:0.844, rnaSEQ:0.719, TFs:0.980], roc[ACC:0.788, rnSEQ:0.644, TFs:0.773]\n",
            "05/31 03:41:07 AM | TRAINING: Epoch: 1, Batch: 6550/11962, Loss: 0.124, perc_uncertainty: 0.005, custom[ACC:0.883, rnaSEQ:0.625, TFs:0.977], roc[ACC:0.843, rnSEQ:0.577, TFs:0.832]\n",
            "05/31 03:41:30 AM | TRAINING: Epoch: 1, Batch: 6600/11962, Loss: 0.120, perc_uncertainty: 0.003, custom[ACC:0.883, rnaSEQ:0.727, TFs:0.977], roc[ACC:0.844, rnSEQ:0.481, TFs:0.746]\n",
            "05/31 03:41:55 AM | TRAINING: Epoch: 1, Batch: 6650/11962, Loss: 0.121, perc_uncertainty: 0.005, custom[ACC:0.875, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.796, rnSEQ:0.519, TFs:0.765]\n",
            "05/31 03:42:19 AM | TRAINING: Epoch: 1, Batch: 6700/11962, Loss: 0.114, perc_uncertainty: 0.005, custom[ACC:0.898, rnaSEQ:0.641, TFs:0.984], roc[ACC:0.822, rnSEQ:0.595, TFs:0.587]\n",
            "05/31 03:42:43 AM | TRAINING: Epoch: 1, Batch: 6750/11962, Loss: 0.121, perc_uncertainty: 0.005, custom[ACC:0.898, rnaSEQ:0.656, TFs:0.980], roc[ACC:0.849, rnSEQ:0.542, TFs:0.702]\n",
            "05/31 03:43:08 AM | TRAINING: Epoch: 1, Batch: 6800/11962, Loss: 0.126, perc_uncertainty: 0.004, custom[ACC:0.867, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.853, rnSEQ:0.579, TFs:0.798]\n",
            "05/31 03:43:32 AM | TRAINING: Epoch: 1, Batch: 6850/11962, Loss: 0.128, perc_uncertainty: 0.005, custom[ACC:0.902, rnaSEQ:0.656, TFs:0.977], roc[ACC:0.839, rnSEQ:0.608, TFs:0.698]\n",
            "05/31 03:43:57 AM | TRAINING: Epoch: 1, Batch: 6900/11962, Loss: 0.110, perc_uncertainty: 0.005, custom[ACC:0.902, rnaSEQ:0.641, TFs:0.984], roc[ACC:0.787, rnSEQ:0.637, TFs:0.731]\n",
            "05/31 03:44:21 AM | TRAINING: Epoch: 1, Batch: 6950/11962, Loss: 0.127, perc_uncertainty: 0.006, custom[ACC:0.855, rnaSEQ:0.742, TFs:0.977], roc[ACC:0.742, rnSEQ:0.489, TFs:0.774]\n",
            "05/31 03:44:45 AM | TRAINING: Epoch: 1, Batch: 7000/11962, Loss: 0.088, perc_uncertainty: 0.003, custom[ACC:0.918, rnaSEQ:0.656, TFs:0.992], roc[ACC:0.721, rnSEQ:0.528, TFs:0.671]\n",
            "05/31 03:45:09 AM | TRAINING: Epoch: 1, Batch: 7050/11962, Loss: 0.130, perc_uncertainty: 0.004, custom[ACC:0.875, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.774, rnSEQ:0.634, TFs:0.621]\n",
            "05/31 03:45:33 AM | TRAINING: Epoch: 1, Batch: 7100/11962, Loss: 0.115, perc_uncertainty: 0.005, custom[ACC:0.875, rnaSEQ:0.695, TFs:0.984], roc[ACC:0.800, rnSEQ:0.448, TFs:0.712]\n",
            "05/31 03:45:56 AM | TRAINING: Epoch: 1, Batch: 7150/11962, Loss: 0.141, perc_uncertainty: 0.006, custom[ACC:0.898, rnaSEQ:0.625, TFs:0.969], roc[ACC:0.882, rnSEQ:0.543, TFs:0.739]\n",
            "05/31 03:46:20 AM | TRAINING: Epoch: 1, Batch: 7200/11962, Loss: 0.120, perc_uncertainty: 0.005, custom[ACC:0.867, rnaSEQ:0.633, TFs:0.980], roc[ACC:0.798, rnSEQ:0.542, TFs:0.598]\n",
            "05/31 03:46:44 AM | TRAINING: Epoch: 1, Batch: 7250/11962, Loss: 0.140, perc_uncertainty: 0.004, custom[ACC:0.855, rnaSEQ:0.633, TFs:0.977], roc[ACC:0.801, rnSEQ:0.574, TFs:0.751]\n",
            "05/31 03:47:09 AM | TRAINING: Epoch: 1, Batch: 7300/11962, Loss: 0.104, perc_uncertainty: 0.006, custom[ACC:0.844, rnaSEQ:0.703, TFs:0.988], roc[ACC:0.843, rnSEQ:0.571, TFs:0.759]\n",
            "05/31 03:47:32 AM | TRAINING: Epoch: 1, Batch: 7350/11962, Loss: 0.133, perc_uncertainty: 0.005, custom[ACC:0.805, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.828, rnSEQ:0.615, TFs:0.700]\n",
            "05/31 03:47:57 AM | TRAINING: Epoch: 1, Batch: 7400/11962, Loss: 0.128, perc_uncertainty: 0.005, custom[ACC:0.844, rnaSEQ:0.695, TFs:0.984], roc[ACC:0.824, rnSEQ:0.513, TFs:0.716]\n",
            "05/31 03:48:22 AM | TRAINING: Epoch: 1, Batch: 7450/11962, Loss: 0.124, perc_uncertainty: 0.005, custom[ACC:0.863, rnaSEQ:0.594, TFs:0.977], roc[ACC:0.778, rnSEQ:0.516, TFs:0.723]\n",
            "05/31 03:48:45 AM | TRAINING: Epoch: 1, Batch: 7500/11962, Loss: 0.106, perc_uncertainty: 0.005, custom[ACC:0.930, rnaSEQ:0.656, TFs:0.984], roc[ACC:0.902, rnSEQ:0.580, TFs:0.736]\n",
            "05/31 03:49:10 AM | TRAINING: Epoch: 1, Batch: 7550/11962, Loss: 0.128, perc_uncertainty: 0.006, custom[ACC:0.840, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.751, rnSEQ:0.567, TFs:0.786]\n",
            "05/31 03:49:33 AM | TRAINING: Epoch: 1, Batch: 7600/11962, Loss: 0.143, perc_uncertainty: 0.005, custom[ACC:0.902, rnaSEQ:0.656, TFs:0.969], roc[ACC:0.814, rnSEQ:0.534, TFs:0.770]\n",
            "05/31 03:49:58 AM | TRAINING: Epoch: 1, Batch: 7650/11962, Loss: 0.119, perc_uncertainty: 0.005, custom[ACC:0.855, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.796, rnSEQ:0.540, TFs:0.699]\n",
            "05/31 03:50:21 AM | TRAINING: Epoch: 1, Batch: 7700/11962, Loss: 0.125, perc_uncertainty: 0.005, custom[ACC:0.883, rnaSEQ:0.656, TFs:0.969], roc[ACC:0.719, rnSEQ:0.512, TFs:0.788]\n",
            "05/31 03:50:46 AM | TRAINING: Epoch: 1, Batch: 7750/11962, Loss: 0.126, perc_uncertainty: 0.005, custom[ACC:0.879, rnaSEQ:0.641, TFs:0.984], roc[ACC:0.764, rnSEQ:0.532, TFs:0.675]\n",
            "05/31 03:51:09 AM | TRAINING: Epoch: 1, Batch: 7800/11962, Loss: 0.119, perc_uncertainty: 0.006, custom[ACC:0.836, rnaSEQ:0.633, TFs:0.984], roc[ACC:0.797, rnSEQ:0.514, TFs:0.757]\n",
            "05/31 03:51:33 AM | TRAINING: Epoch: 1, Batch: 7850/11962, Loss: 0.119, perc_uncertainty: 0.005, custom[ACC:0.891, rnaSEQ:0.609, TFs:0.977], roc[ACC:0.839, rnSEQ:0.628, TFs:0.759]\n",
            "05/31 03:51:56 AM | TRAINING: Epoch: 1, Batch: 7900/11962, Loss: 0.128, perc_uncertainty: 0.005, custom[ACC:0.859, rnaSEQ:0.625, TFs:0.977], roc[ACC:0.745, rnSEQ:0.603, TFs:0.721]\n",
            "05/31 03:52:20 AM | TRAINING: Epoch: 1, Batch: 7950/11962, Loss: 0.127, perc_uncertainty: 0.005, custom[ACC:0.848, rnaSEQ:0.664, TFs:0.977], roc[ACC:0.829, rnSEQ:0.485, TFs:0.834]\n",
            "05/31 03:52:44 AM | TRAINING: Epoch: 1, Batch: 8000/11962, Loss: 0.121, perc_uncertainty: 0.005, custom[ACC:0.902, rnaSEQ:0.617, TFs:0.984], roc[ACC:0.816, rnSEQ:0.597, TFs:0.712]\n",
            "05/31 03:53:09 AM | TRAINING: Epoch: 1, Batch: 8050/11962, Loss: 0.119, perc_uncertainty: 0.006, custom[ACC:0.855, rnaSEQ:0.633, TFs:0.977], roc[ACC:0.828, rnSEQ:0.566, TFs:0.735]\n",
            "05/31 03:53:32 AM | TRAINING: Epoch: 1, Batch: 8100/11962, Loss: 0.099, perc_uncertainty: 0.004, custom[ACC:0.875, rnaSEQ:0.719, TFs:0.992], roc[ACC:0.739, rnSEQ:0.486, TFs:0.713]\n",
            "05/31 03:53:57 AM | TRAINING: Epoch: 1, Batch: 8150/11962, Loss: 0.108, perc_uncertainty: 0.004, custom[ACC:0.871, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.835, rnSEQ:0.631, TFs:0.666]\n",
            "05/31 03:54:21 AM | TRAINING: Epoch: 1, Batch: 8200/11962, Loss: 0.111, perc_uncertainty: 0.005, custom[ACC:0.902, rnaSEQ:0.703, TFs:0.980], roc[ACC:0.850, rnSEQ:0.567, TFs:0.758]\n",
            "05/31 03:54:45 AM | TRAINING: Epoch: 1, Batch: 8250/11962, Loss: 0.130, perc_uncertainty: 0.005, custom[ACC:0.930, rnaSEQ:0.664, TFs:0.977], roc[ACC:0.849, rnSEQ:0.515, TFs:0.718]\n",
            "05/31 03:55:09 AM | TRAINING: Epoch: 1, Batch: 8300/11962, Loss: 0.126, perc_uncertainty: 0.005, custom[ACC:0.891, rnaSEQ:0.633, TFs:0.977], roc[ACC:0.809, rnSEQ:0.484, TFs:0.804]\n",
            "05/31 03:55:33 AM | TRAINING: Epoch: 1, Batch: 8350/11962, Loss: 0.114, perc_uncertainty: 0.007, custom[ACC:0.859, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.852, rnSEQ:0.577, TFs:0.778]\n",
            "05/31 03:55:58 AM | TRAINING: Epoch: 1, Batch: 8400/11962, Loss: 0.124, perc_uncertainty: 0.004, custom[ACC:0.887, rnaSEQ:0.688, TFs:0.980], roc[ACC:0.825, rnSEQ:0.622, TFs:0.750]\n",
            "05/31 03:56:22 AM | TRAINING: Epoch: 1, Batch: 8450/11962, Loss: 0.150, perc_uncertainty: 0.005, custom[ACC:0.879, rnaSEQ:0.680, TFs:0.969], roc[ACC:0.862, rnSEQ:0.571, TFs:0.708]\n",
            "05/31 03:56:46 AM | TRAINING: Epoch: 1, Batch: 8500/11962, Loss: 0.106, perc_uncertainty: 0.005, custom[ACC:0.922, rnaSEQ:0.609, TFs:0.984], roc[ACC:0.815, rnSEQ:0.604, TFs:0.554]\n",
            "05/31 03:57:09 AM | TRAINING: Epoch: 1, Batch: 8550/11962, Loss: 0.137, perc_uncertainty: 0.006, custom[ACC:0.871, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.834, rnSEQ:0.513, TFs:0.751]\n",
            "05/31 03:57:33 AM | TRAINING: Epoch: 1, Batch: 8600/11962, Loss: 0.117, perc_uncertainty: 0.005, custom[ACC:0.910, rnaSEQ:0.625, TFs:0.977], roc[ACC:0.832, rnSEQ:0.587, TFs:0.715]\n",
            "05/31 03:57:56 AM | TRAINING: Epoch: 1, Batch: 8650/11962, Loss: 0.123, perc_uncertainty: 0.006, custom[ACC:0.863, rnaSEQ:0.617, TFs:0.977], roc[ACC:0.894, rnSEQ:0.638, TFs:0.816]\n",
            "05/31 03:58:21 AM | TRAINING: Epoch: 1, Batch: 8700/11962, Loss: 0.124, perc_uncertainty: 0.006, custom[ACC:0.891, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.845, rnSEQ:0.573, TFs:0.655]\n",
            "05/31 03:58:45 AM | TRAINING: Epoch: 1, Batch: 8750/11962, Loss: 0.118, perc_uncertainty: 0.005, custom[ACC:0.832, rnaSEQ:0.648, TFs:0.977], roc[ACC:0.811, rnSEQ:0.512, TFs:0.775]\n",
            "05/31 03:59:10 AM | TRAINING: Epoch: 1, Batch: 8800/11962, Loss: 0.131, perc_uncertainty: 0.004, custom[ACC:0.883, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.797, rnSEQ:0.486, TFs:0.689]\n",
            "05/31 03:59:33 AM | TRAINING: Epoch: 1, Batch: 8850/11962, Loss: 0.138, perc_uncertainty: 0.004, custom[ACC:0.852, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.817, rnSEQ:0.592, TFs:0.739]\n",
            "05/31 03:59:58 AM | TRAINING: Epoch: 1, Batch: 8900/11962, Loss: 0.100, perc_uncertainty: 0.004, custom[ACC:0.902, rnaSEQ:0.648, TFs:0.988], roc[ACC:0.864, rnSEQ:0.559, TFs:0.688]\n",
            "05/31 04:00:21 AM | TRAINING: Epoch: 1, Batch: 8950/11962, Loss: 0.128, perc_uncertainty: 0.004, custom[ACC:0.863, rnaSEQ:0.648, TFs:0.980], roc[ACC:0.669, rnSEQ:0.538, TFs:0.657]\n",
            "05/31 04:00:45 AM | TRAINING: Epoch: 1, Batch: 9000/11962, Loss: 0.120, perc_uncertainty: 0.006, custom[ACC:0.852, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.875, rnSEQ:0.506, TFs:0.810]\n",
            "05/31 04:01:08 AM | TRAINING: Epoch: 1, Batch: 9050/11962, Loss: 0.108, perc_uncertainty: 0.005, custom[ACC:0.867, rnaSEQ:0.672, TFs:0.977], roc[ACC:0.781, rnSEQ:0.614, TFs:0.763]\n",
            "05/31 04:01:32 AM | TRAINING: Epoch: 1, Batch: 9100/11962, Loss: 0.124, perc_uncertainty: 0.004, custom[ACC:0.875, rnaSEQ:0.648, TFs:0.984], roc[ACC:0.788, rnSEQ:0.566, TFs:0.773]\n",
            "05/31 04:01:55 AM | TRAINING: Epoch: 1, Batch: 9150/11962, Loss: 0.139, perc_uncertainty: 0.006, custom[ACC:0.863, rnaSEQ:0.719, TFs:0.969], roc[ACC:0.803, rnSEQ:0.609, TFs:0.770]\n",
            "05/31 04:02:20 AM | TRAINING: Epoch: 1, Batch: 9200/11962, Loss: 0.101, perc_uncertainty: 0.005, custom[ACC:0.898, rnaSEQ:0.695, TFs:0.984], roc[ACC:0.860, rnSEQ:0.523, TFs:0.701]\n",
            "05/31 04:02:44 AM | TRAINING: Epoch: 1, Batch: 9250/11962, Loss: 0.124, perc_uncertainty: 0.006, custom[ACC:0.863, rnaSEQ:0.578, TFs:0.977], roc[ACC:0.780, rnSEQ:0.550, TFs:0.686]\n",
            "05/31 04:03:09 AM | TRAINING: Epoch: 1, Batch: 9300/11962, Loss: 0.103, perc_uncertainty: 0.006, custom[ACC:0.895, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.760, rnSEQ:0.566, TFs:0.715]\n",
            "05/31 04:03:32 AM | TRAINING: Epoch: 1, Batch: 9350/11962, Loss: 0.115, perc_uncertainty: 0.005, custom[ACC:0.863, rnaSEQ:0.586, TFs:0.977], roc[ACC:0.866, rnSEQ:0.537, TFs:0.733]\n",
            "05/31 04:03:57 AM | TRAINING: Epoch: 1, Batch: 9400/11962, Loss: 0.123, perc_uncertainty: 0.005, custom[ACC:0.863, rnaSEQ:0.633, TFs:0.984], roc[ACC:0.811, rnSEQ:0.552, TFs:0.686]\n",
            "05/31 04:04:21 AM | TRAINING: Epoch: 1, Batch: 9450/11962, Loss: 0.139, perc_uncertainty: 0.006, custom[ACC:0.848, rnaSEQ:0.656, TFs:0.969], roc[ACC:0.762, rnSEQ:0.481, TFs:0.803]\n",
            "05/31 04:04:44 AM | TRAINING: Epoch: 1, Batch: 9500/11962, Loss: 0.121, perc_uncertainty: 0.005, custom[ACC:0.863, rnaSEQ:0.625, TFs:0.984], roc[ACC:0.831, rnSEQ:0.561, TFs:0.782]\n",
            "05/31 04:05:08 AM | TRAINING: Epoch: 1, Batch: 9550/11962, Loss: 0.127, perc_uncertainty: 0.005, custom[ACC:0.859, rnaSEQ:0.805, TFs:0.973], roc[ACC:0.821, rnSEQ:0.626, TFs:0.762]\n",
            "05/31 04:05:32 AM | TRAINING: Epoch: 1, Batch: 9600/11962, Loss: 0.097, perc_uncertainty: 0.005, custom[ACC:0.883, rnaSEQ:0.656, TFs:0.992], roc[ACC:0.818, rnSEQ:0.616, TFs:0.740]\n",
            "05/31 04:05:56 AM | TRAINING: Epoch: 1, Batch: 9650/11962, Loss: 0.110, perc_uncertainty: 0.004, custom[ACC:0.910, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.784, rnSEQ:0.555, TFs:0.739]\n",
            "05/31 04:06:21 AM | TRAINING: Epoch: 1, Batch: 9700/11962, Loss: 0.108, perc_uncertainty: 0.005, custom[ACC:0.898, rnaSEQ:0.688, TFs:0.980], roc[ACC:0.717, rnSEQ:0.608, TFs:0.804]\n",
            "05/31 04:06:45 AM | TRAINING: Epoch: 1, Batch: 9750/11962, Loss: 0.140, perc_uncertainty: 0.007, custom[ACC:0.875, rnaSEQ:0.664, TFs:0.969], roc[ACC:0.842, rnSEQ:0.656, TFs:0.802]\n",
            "05/31 04:07:08 AM | TRAINING: Epoch: 1, Batch: 9800/11962, Loss: 0.131, perc_uncertainty: 0.007, custom[ACC:0.914, rnaSEQ:0.758, TFs:0.969], roc[ACC:0.881, rnSEQ:0.649, TFs:0.780]\n",
            "05/31 04:07:32 AM | TRAINING: Epoch: 1, Batch: 9850/11962, Loss: 0.119, perc_uncertainty: 0.005, custom[ACC:0.883, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.810, rnSEQ:0.593, TFs:0.714]\n",
            "05/31 04:07:57 AM | TRAINING: Epoch: 1, Batch: 9900/11962, Loss: 0.121, perc_uncertainty: 0.005, custom[ACC:0.883, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.756, rnSEQ:0.670, TFs:0.820]\n",
            "05/31 04:08:20 AM | TRAINING: Epoch: 1, Batch: 9950/11962, Loss: 0.120, perc_uncertainty: 0.006, custom[ACC:0.871, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.681, rnSEQ:0.420, TFs:0.801]\n",
            "05/31 04:08:44 AM | TRAINING: Epoch: 1, Batch: 10000/11962, Loss: 0.110, perc_uncertainty: 0.005, custom[ACC:0.871, rnaSEQ:0.719, TFs:0.980], roc[ACC:0.823, rnSEQ:0.469, TFs:0.674]\n",
            "05/31 04:09:09 AM | TRAINING: Epoch: 1, Batch: 10050/11962, Loss: 0.112, perc_uncertainty: 0.006, custom[ACC:0.867, rnaSEQ:0.688, TFs:0.984], roc[ACC:0.782, rnSEQ:0.575, TFs:0.727]\n",
            "05/31 04:09:32 AM | TRAINING: Epoch: 1, Batch: 10100/11962, Loss: 0.111, perc_uncertainty: 0.005, custom[ACC:0.875, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.792, rnSEQ:0.587, TFs:0.641]\n",
            "05/31 04:09:57 AM | TRAINING: Epoch: 1, Batch: 10150/11962, Loss: 0.107, perc_uncertainty: 0.005, custom[ACC:0.906, rnaSEQ:0.617, TFs:0.984], roc[ACC:0.783, rnSEQ:0.536, TFs:0.687]\n",
            "05/31 04:10:20 AM | TRAINING: Epoch: 1, Batch: 10200/11962, Loss: 0.142, perc_uncertainty: 0.007, custom[ACC:0.863, rnaSEQ:0.695, TFs:0.969], roc[ACC:0.823, rnSEQ:0.685, TFs:0.715]\n",
            "05/31 04:10:44 AM | TRAINING: Epoch: 1, Batch: 10250/11962, Loss: 0.135, perc_uncertainty: 0.005, custom[ACC:0.879, rnaSEQ:0.672, TFs:0.977], roc[ACC:0.704, rnSEQ:0.533, TFs:0.722]\n",
            "05/31 04:11:07 AM | TRAINING: Epoch: 1, Batch: 10300/11962, Loss: 0.105, perc_uncertainty: 0.006, custom[ACC:0.871, rnaSEQ:0.633, TFs:0.984], roc[ACC:0.858, rnSEQ:0.581, TFs:0.733]\n",
            "05/31 04:11:32 AM | TRAINING: Epoch: 1, Batch: 10350/11962, Loss: 0.106, perc_uncertainty: 0.005, custom[ACC:0.887, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.780, rnSEQ:0.532, TFs:0.631]\n",
            "05/31 04:11:55 AM | TRAINING: Epoch: 1, Batch: 10400/11962, Loss: 0.120, perc_uncertainty: 0.006, custom[ACC:0.898, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.740, rnSEQ:0.590, TFs:0.717]\n",
            "05/31 04:12:20 AM | TRAINING: Epoch: 1, Batch: 10450/11962, Loss: 0.129, perc_uncertainty: 0.008, custom[ACC:0.863, rnaSEQ:0.672, TFs:0.969], roc[ACC:0.830, rnSEQ:0.649, TFs:0.806]\n",
            "05/31 04:12:44 AM | TRAINING: Epoch: 1, Batch: 10500/11962, Loss: 0.115, perc_uncertainty: 0.005, custom[ACC:0.852, rnaSEQ:0.742, TFs:0.984], roc[ACC:0.743, rnSEQ:0.566, TFs:0.801]\n",
            "05/31 04:13:09 AM | TRAINING: Epoch: 1, Batch: 10550/11962, Loss: 0.131, perc_uncertainty: 0.006, custom[ACC:0.898, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.911, rnSEQ:0.552, TFs:0.810]\n",
            "05/31 04:13:32 AM | TRAINING: Epoch: 1, Batch: 10600/11962, Loss: 0.102, perc_uncertainty: 0.004, custom[ACC:0.879, rnaSEQ:0.609, TFs:0.984], roc[ACC:0.724, rnSEQ:0.508, TFs:0.722]\n",
            "05/31 04:13:56 AM | TRAINING: Epoch: 1, Batch: 10650/11962, Loss: 0.116, perc_uncertainty: 0.006, custom[ACC:0.855, rnaSEQ:0.641, TFs:0.984], roc[ACC:0.774, rnSEQ:0.592, TFs:0.762]\n",
            "05/31 04:14:22 AM | TRAINING: Epoch: 1, Batch: 10700/11962, Loss: 0.131, perc_uncertainty: 0.006, custom[ACC:0.840, rnaSEQ:0.703, TFs:0.969], roc[ACC:0.857, rnSEQ:0.631, TFs:0.824]\n",
            "05/31 04:14:45 AM | TRAINING: Epoch: 1, Batch: 10750/11962, Loss: 0.125, perc_uncertainty: 0.006, custom[ACC:0.902, rnaSEQ:0.625, TFs:0.977], roc[ACC:0.814, rnSEQ:0.599, TFs:0.800]\n",
            "05/31 04:15:10 AM | TRAINING: Epoch: 1, Batch: 10800/11962, Loss: 0.127, perc_uncertainty: 0.005, custom[ACC:0.875, rnaSEQ:0.711, TFs:0.977], roc[ACC:0.828, rnSEQ:0.435, TFs:0.750]\n",
            "05/31 04:15:34 AM | TRAINING: Epoch: 1, Batch: 10850/11962, Loss: 0.127, perc_uncertainty: 0.006, custom[ACC:0.828, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.796, rnSEQ:0.537, TFs:0.768]\n",
            "05/31 04:15:58 AM | TRAINING: Epoch: 1, Batch: 10900/11962, Loss: 0.112, perc_uncertainty: 0.005, custom[ACC:0.871, rnaSEQ:0.727, TFs:0.984], roc[ACC:0.807, rnSEQ:0.673, TFs:0.665]\n",
            "05/31 04:16:23 AM | TRAINING: Epoch: 1, Batch: 10950/11962, Loss: 0.109, perc_uncertainty: 0.004, custom[ACC:0.871, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.805, rnSEQ:0.593, TFs:0.664]\n",
            "05/31 04:16:46 AM | TRAINING: Epoch: 1, Batch: 11000/11962, Loss: 0.107, perc_uncertainty: 0.005, custom[ACC:0.891, rnaSEQ:0.672, TFs:0.984], roc[ACC:0.799, rnSEQ:0.596, TFs:0.721]\n",
            "05/31 04:17:11 AM | TRAINING: Epoch: 1, Batch: 11050/11962, Loss: 0.142, perc_uncertainty: 0.007, custom[ACC:0.863, rnaSEQ:0.633, TFs:0.969], roc[ACC:0.853, rnSEQ:0.593, TFs:0.811]\n",
            "05/31 04:17:35 AM | TRAINING: Epoch: 1, Batch: 11100/11962, Loss: 0.123, perc_uncertainty: 0.006, custom[ACC:0.883, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.770, rnSEQ:0.546, TFs:0.787]\n",
            "05/31 04:17:59 AM | TRAINING: Epoch: 1, Batch: 11150/11962, Loss: 0.103, perc_uncertainty: 0.006, custom[ACC:0.926, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.822, rnSEQ:0.537, TFs:0.757]\n",
            "05/31 04:18:22 AM | TRAINING: Epoch: 1, Batch: 11200/11962, Loss: 0.118, perc_uncertainty: 0.006, custom[ACC:0.781, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.774, rnSEQ:0.646, TFs:0.762]\n",
            "05/31 04:18:46 AM | TRAINING: Epoch: 1, Batch: 11250/11962, Loss: 0.111, perc_uncertainty: 0.005, custom[ACC:0.875, rnaSEQ:0.719, TFs:0.984], roc[ACC:0.773, rnSEQ:0.536, TFs:0.723]\n",
            "05/31 04:19:09 AM | TRAINING: Epoch: 1, Batch: 11300/11962, Loss: 0.117, perc_uncertainty: 0.005, custom[ACC:0.855, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.788, rnSEQ:0.660, TFs:0.794]\n",
            "05/31 04:19:34 AM | TRAINING: Epoch: 1, Batch: 11350/11962, Loss: 0.111, perc_uncertainty: 0.007, custom[ACC:0.844, rnaSEQ:0.609, TFs:0.977], roc[ACC:0.855, rnSEQ:0.542, TFs:0.707]\n",
            "05/31 04:19:57 AM | TRAINING: Epoch: 1, Batch: 11400/11962, Loss: 0.124, perc_uncertainty: 0.005, custom[ACC:0.863, rnaSEQ:0.641, TFs:0.977], roc[ACC:0.713, rnSEQ:0.600, TFs:0.645]\n",
            "05/31 04:20:22 AM | TRAINING: Epoch: 1, Batch: 11450/11962, Loss: 0.133, perc_uncertainty: 0.006, custom[ACC:0.863, rnaSEQ:0.727, TFs:0.977], roc[ACC:0.770, rnSEQ:0.589, TFs:0.733]\n",
            "05/31 04:20:46 AM | TRAINING: Epoch: 1, Batch: 11500/11962, Loss: 0.103, perc_uncertainty: 0.005, custom[ACC:0.887, rnaSEQ:0.695, TFs:0.984], roc[ACC:0.863, rnSEQ:0.639, TFs:0.720]\n",
            "05/31 04:21:11 AM | TRAINING: Epoch: 1, Batch: 11550/11962, Loss: 0.120, perc_uncertainty: 0.006, custom[ACC:0.797, rnaSEQ:0.742, TFs:0.984], roc[ACC:0.797, rnSEQ:0.578, TFs:0.596]\n",
            "05/31 04:21:34 AM | TRAINING: Epoch: 1, Batch: 11600/11962, Loss: 0.130, perc_uncertainty: 0.007, custom[ACC:0.828, rnaSEQ:0.781, TFs:0.977], roc[ACC:0.820, rnSEQ:0.652, TFs:0.787]\n",
            "05/31 04:21:58 AM | TRAINING: Epoch: 1, Batch: 11650/11962, Loss: 0.103, perc_uncertainty: 0.007, custom[ACC:0.832, rnaSEQ:0.594, TFs:0.984], roc[ACC:0.774, rnSEQ:0.575, TFs:0.641]\n",
            "05/31 04:22:23 AM | TRAINING: Epoch: 1, Batch: 11700/11962, Loss: 0.124, perc_uncertainty: 0.006, custom[ACC:0.887, rnaSEQ:0.727, TFs:0.977], roc[ACC:0.744, rnSEQ:0.518, TFs:0.765]\n",
            "05/31 04:22:46 AM | TRAINING: Epoch: 1, Batch: 11750/11962, Loss: 0.116, perc_uncertainty: 0.005, custom[ACC:0.867, rnaSEQ:0.633, TFs:0.977], roc[ACC:0.759, rnSEQ:0.587, TFs:0.777]\n",
            "05/31 04:23:11 AM | TRAINING: Epoch: 1, Batch: 11800/11962, Loss: 0.102, perc_uncertainty: 0.005, custom[ACC:0.855, rnaSEQ:0.602, TFs:0.984], roc[ACC:0.766, rnSEQ:0.673, TFs:0.697]\n",
            "05/31 04:23:34 AM | TRAINING: Epoch: 1, Batch: 11850/11962, Loss: 0.124, perc_uncertainty: 0.007, custom[ACC:0.895, rnaSEQ:0.648, TFs:0.977], roc[ACC:0.807, rnSEQ:0.495, TFs:0.823]\n",
            "05/31 04:23:58 AM | TRAINING: Epoch: 1, Batch: 11900/11962, Loss: 0.124, perc_uncertainty: 0.005, custom[ACC:0.840, rnaSEQ:0.734, TFs:0.977], roc[ACC:0.725, rnSEQ:0.543, TFs:0.713]\n",
            "05/31 04:24:23 AM | TRAINING: Epoch: 1, Batch: 11950/11962, Loss: 0.110, perc_uncertainty: 0.004, custom[ACC:0.863, rnaSEQ:0.711, TFs:0.984], roc[ACC:0.744, rnSEQ:0.487, TFs:0.556]\n",
            "05/31 04:24:28 AM | TRAINING: Epoch: 1, Batch: 11962/11962, Loss: 0.093, perc_uncertainty: 0.005, custom[ACC:1.000, rnaSEQ:0.625, TFs:1.000], roc[ACC:0.500, rnSEQ:0.500, TFs:0.000]\n",
            "05/31 04:24:29 AM | VALIDATION: Batch: 0/730, Loss: 0.106, perc_uncertainty: 0.000, custom[ACC:0.898, rnaSEQ:0.656, TFs:0.984], roc[ACC: 0.837, rnSEQ: 0.477, TFs:0.760]\n",
            "05/31 04:24:38 AM | VALIDATION: Batch: 50/730, Loss: 0.128, perc_uncertainty: 0.328, custom[ACC:0.875, rnaSEQ:0.648, TFs:0.969], roc[ACC: 0.780, rnSEQ: 0.544, TFs:0.771]\n",
            "05/31 04:24:46 AM | VALIDATION: Batch: 100/730, Loss: 0.108, perc_uncertainty: 0.661, custom[ACC:0.906, rnaSEQ:0.664, TFs:0.977], roc[ACC: 0.822, rnSEQ: 0.613, TFs:0.781]\n",
            "05/31 04:24:55 AM | VALIDATION: Batch: 150/730, Loss: 0.110, perc_uncertainty: 1.035, custom[ACC:0.910, rnaSEQ:0.594, TFs:0.984], roc[ACC: 0.814, rnSEQ: 0.596, TFs:0.786]\n",
            "05/31 04:25:03 AM | VALIDATION: Batch: 200/730, Loss: 0.138, perc_uncertainty: 1.353, custom[ACC:0.891, rnaSEQ:0.656, TFs:0.977], roc[ACC: 0.750, rnSEQ: 0.526, TFs:0.737]\n",
            "05/31 04:25:12 AM | VALIDATION: Batch: 250/730, Loss: 0.114, perc_uncertainty: 1.704, custom[ACC:0.906, rnaSEQ:0.625, TFs:0.984], roc[ACC: 0.733, rnSEQ: 0.562, TFs:0.655]\n",
            "05/31 04:25:21 AM | VALIDATION: Batch: 300/730, Loss: 0.115, perc_uncertainty: 2.054, custom[ACC:0.922, rnaSEQ:0.562, TFs:0.977], roc[ACC: 0.838, rnSEQ: 0.603, TFs:0.759]\n",
            "05/31 04:25:30 AM | VALIDATION: Batch: 350/730, Loss: 0.110, perc_uncertainty: 2.405, custom[ACC:0.891, rnaSEQ:0.625, TFs:0.984], roc[ACC: 0.781, rnSEQ: 0.578, TFs:0.750]\n",
            "05/31 04:25:39 AM | VALIDATION: Batch: 400/730, Loss: 0.125, perc_uncertainty: 2.743, custom[ACC:0.867, rnaSEQ:0.688, TFs:0.977], roc[ACC: 0.749, rnSEQ: 0.686, TFs:0.751]\n",
            "05/31 04:25:48 AM | VALIDATION: Batch: 450/730, Loss: 0.101, perc_uncertainty: 3.092, custom[ACC:0.898, rnaSEQ:0.688, TFs:0.984], roc[ACC: 0.808, rnSEQ: 0.621, TFs:0.703]\n",
            "05/31 04:25:57 AM | VALIDATION: Batch: 500/730, Loss: 0.109, perc_uncertainty: 3.420, custom[ACC:0.906, rnaSEQ:0.664, TFs:0.977], roc[ACC: 0.847, rnSEQ: 0.553, TFs:0.821]\n",
            "05/31 04:26:05 AM | VALIDATION: Batch: 550/730, Loss: 0.108, perc_uncertainty: 3.761, custom[ACC:0.887, rnaSEQ:0.609, TFs:0.984], roc[ACC: 0.854, rnSEQ: 0.655, TFs:0.702]\n",
            "05/31 04:26:14 AM | VALIDATION: Batch: 600/730, Loss: 0.101, perc_uncertainty: 4.094, custom[ACC:0.945, rnaSEQ:0.547, TFs:0.984], roc[ACC: 0.875, rnSEQ: 0.604, TFs:0.879]\n",
            "05/31 04:26:22 AM | VALIDATION: Batch: 650/730, Loss: 0.122, perc_uncertainty: 4.424, custom[ACC:0.902, rnaSEQ:0.703, TFs:0.977], roc[ACC: 0.873, rnSEQ: 0.647, TFs:0.757]\n",
            "05/31 04:26:31 AM | VALIDATION: Batch: 700/730, Loss: 0.118, perc_uncertainty: 4.760, custom[ACC:0.871, rnaSEQ:0.586, TFs:0.977], roc[ACC: 0.828, rnSEQ: 0.516, TFs:0.729]\n",
            "05/31 04:26:36 AM | VALIDATION: Batch: 730/730, Loss: 0.101, perc_uncertainty: 4.962, custom[ACC:0.913, rnaSEQ:0.522, TFs:1.000], roc[ACC: 0.631, rnSEQ: 0.492, TFs:0.000]\n",
            "05/31 04:26:36 AM | percentage of uncertainty in validation prediction: 0.006789221739993088\n",
            "05/31 04:26:38 AM | TRAINING: Epoch: 2, Batch: 0/11962, Loss: 0.111, perc_uncertainty: 0.006, custom[ACC:0.867, rnaSEQ:0.766, TFs:0.984], roc[ACC:0.745, rnSEQ:0.476, TFs:0.802]\n",
            "05/31 04:27:02 AM | TRAINING: Epoch: 2, Batch: 50/11962, Loss: 0.117, perc_uncertainty: 0.005, custom[ACC:0.863, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.870, rnSEQ:0.601, TFs:0.757]\n",
            "05/31 04:27:25 AM | TRAINING: Epoch: 2, Batch: 100/11962, Loss: 0.100, perc_uncertainty: 0.005, custom[ACC:0.910, rnaSEQ:0.648, TFs:0.984], roc[ACC:0.804, rnSEQ:0.593, TFs:0.732]\n",
            "05/31 04:27:49 AM | TRAINING: Epoch: 2, Batch: 150/11962, Loss: 0.109, perc_uncertainty: 0.006, custom[ACC:0.879, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.640, rnSEQ:0.575, TFs:0.755]\n",
            "05/31 04:28:12 AM | TRAINING: Epoch: 2, Batch: 200/11962, Loss: 0.110, perc_uncertainty: 0.006, custom[ACC:0.836, rnaSEQ:0.594, TFs:0.984], roc[ACC:0.739, rnSEQ:0.594, TFs:0.813]\n",
            "05/31 04:28:36 AM | TRAINING: Epoch: 2, Batch: 250/11962, Loss: 0.121, perc_uncertainty: 0.005, custom[ACC:0.852, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.719, rnSEQ:0.644, TFs:0.712]\n",
            "05/31 04:28:59 AM | TRAINING: Epoch: 2, Batch: 300/11962, Loss: 0.099, perc_uncertainty: 0.005, custom[ACC:0.902, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.890, rnSEQ:0.526, TFs:0.712]\n",
            "05/31 04:29:22 AM | TRAINING: Epoch: 2, Batch: 350/11962, Loss: 0.096, perc_uncertainty: 0.007, custom[ACC:0.918, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.883, rnSEQ:0.611, TFs:0.837]\n",
            "05/31 04:29:46 AM | TRAINING: Epoch: 2, Batch: 400/11962, Loss: 0.101, perc_uncertainty: 0.006, custom[ACC:0.848, rnaSEQ:0.695, TFs:0.984], roc[ACC:0.830, rnSEQ:0.655, TFs:0.774]\n",
            "05/31 04:30:10 AM | TRAINING: Epoch: 2, Batch: 450/11962, Loss: 0.109, perc_uncertainty: 0.006, custom[ACC:0.887, rnaSEQ:0.719, TFs:0.984], roc[ACC:0.836, rnSEQ:0.492, TFs:0.773]\n",
            "05/31 04:30:33 AM | TRAINING: Epoch: 2, Batch: 500/11962, Loss: 0.098, perc_uncertainty: 0.005, custom[ACC:0.871, rnaSEQ:0.680, TFs:0.984], roc[ACC:0.833, rnSEQ:0.637, TFs:0.760]\n",
            "05/31 04:30:56 AM | TRAINING: Epoch: 2, Batch: 550/11962, Loss: 0.112, perc_uncertainty: 0.005, custom[ACC:0.902, rnaSEQ:0.625, TFs:0.977], roc[ACC:0.911, rnSEQ:0.561, TFs:0.862]\n",
            "05/31 04:31:20 AM | TRAINING: Epoch: 2, Batch: 600/11962, Loss: 0.108, perc_uncertainty: 0.005, custom[ACC:0.840, rnaSEQ:0.773, TFs:0.984], roc[ACC:0.818, rnSEQ:0.520, TFs:0.733]\n",
            "05/31 04:31:43 AM | TRAINING: Epoch: 2, Batch: 650/11962, Loss: 0.124, perc_uncertainty: 0.007, custom[ACC:0.879, rnaSEQ:0.625, TFs:0.977], roc[ACC:0.785, rnSEQ:0.579, TFs:0.784]\n",
            "05/31 04:32:07 AM | TRAINING: Epoch: 2, Batch: 700/11962, Loss: 0.119, perc_uncertainty: 0.006, custom[ACC:0.844, rnaSEQ:0.648, TFs:0.980], roc[ACC:0.801, rnSEQ:0.604, TFs:0.738]\n",
            "05/31 04:32:30 AM | TRAINING: Epoch: 2, Batch: 750/11962, Loss: 0.122, perc_uncertainty: 0.007, custom[ACC:0.891, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.798, rnSEQ:0.497, TFs:0.694]\n",
            "05/31 04:32:54 AM | TRAINING: Epoch: 2, Batch: 800/11962, Loss: 0.131, perc_uncertainty: 0.006, custom[ACC:0.816, rnaSEQ:0.734, TFs:0.977], roc[ACC:0.762, rnSEQ:0.507, TFs:0.808]\n",
            "05/31 04:33:17 AM | TRAINING: Epoch: 2, Batch: 850/11962, Loss: 0.107, perc_uncertainty: 0.004, custom[ACC:0.879, rnaSEQ:0.648, TFs:0.984], roc[ACC:0.703, rnSEQ:0.620, TFs:0.795]\n",
            "05/31 04:33:40 AM | TRAINING: Epoch: 2, Batch: 900/11962, Loss: 0.137, perc_uncertainty: 0.006, custom[ACC:0.848, rnaSEQ:0.719, TFs:0.969], roc[ACC:0.734, rnSEQ:0.575, TFs:0.781]\n",
            "05/31 04:34:04 AM | TRAINING: Epoch: 2, Batch: 950/11962, Loss: 0.110, perc_uncertainty: 0.006, custom[ACC:0.879, rnaSEQ:0.609, TFs:0.984], roc[ACC:0.812, rnSEQ:0.582, TFs:0.703]\n",
            "05/31 04:34:27 AM | TRAINING: Epoch: 2, Batch: 1000/11962, Loss: 0.115, perc_uncertainty: 0.007, custom[ACC:0.914, rnaSEQ:0.633, TFs:0.977], roc[ACC:0.849, rnSEQ:0.579, TFs:0.828]\n",
            "05/31 04:34:50 AM | TRAINING: Epoch: 2, Batch: 1050/11962, Loss: 0.136, perc_uncertainty: 0.006, custom[ACC:0.863, rnaSEQ:0.672, TFs:0.977], roc[ACC:0.799, rnSEQ:0.565, TFs:0.770]\n",
            "05/31 04:35:14 AM | TRAINING: Epoch: 2, Batch: 1100/11962, Loss: 0.125, perc_uncertainty: 0.006, custom[ACC:0.840, rnaSEQ:0.664, TFs:0.977], roc[ACC:0.800, rnSEQ:0.608, TFs:0.741]\n",
            "05/31 04:35:37 AM | TRAINING: Epoch: 2, Batch: 1150/11962, Loss: 0.125, perc_uncertainty: 0.007, custom[ACC:0.910, rnaSEQ:0.672, TFs:0.977], roc[ACC:0.801, rnSEQ:0.566, TFs:0.713]\n",
            "05/31 04:36:01 AM | TRAINING: Epoch: 2, Batch: 1200/11962, Loss: 0.130, perc_uncertainty: 0.008, custom[ACC:0.902, rnaSEQ:0.633, TFs:0.969], roc[ACC:0.876, rnSEQ:0.590, TFs:0.863]\n",
            "05/31 04:36:24 AM | TRAINING: Epoch: 2, Batch: 1250/11962, Loss: 0.135, perc_uncertainty: 0.006, custom[ACC:0.867, rnaSEQ:0.688, TFs:0.969], roc[ACC:0.843, rnSEQ:0.548, TFs:0.816]\n",
            "05/31 04:36:47 AM | TRAINING: Epoch: 2, Batch: 1300/11962, Loss: 0.124, perc_uncertainty: 0.007, custom[ACC:0.848, rnaSEQ:0.672, TFs:0.977], roc[ACC:0.859, rnSEQ:0.568, TFs:0.852]\n",
            "05/31 04:37:11 AM | TRAINING: Epoch: 2, Batch: 1350/11962, Loss: 0.118, perc_uncertainty: 0.006, custom[ACC:0.832, rnaSEQ:0.617, TFs:0.977], roc[ACC:0.789, rnSEQ:0.647, TFs:0.823]\n",
            "05/31 04:37:34 AM | TRAINING: Epoch: 2, Batch: 1400/11962, Loss: 0.113, perc_uncertainty: 0.006, custom[ACC:0.902, rnaSEQ:0.688, TFs:0.984], roc[ACC:0.741, rnSEQ:0.627, TFs:0.734]\n",
            "05/31 04:37:58 AM | TRAINING: Epoch: 2, Batch: 1450/11962, Loss: 0.115, perc_uncertainty: 0.005, custom[ACC:0.875, rnaSEQ:0.570, TFs:0.984], roc[ACC:0.803, rnSEQ:0.533, TFs:0.644]\n",
            "05/31 04:38:21 AM | TRAINING: Epoch: 2, Batch: 1500/11962, Loss: 0.106, perc_uncertainty: 0.005, custom[ACC:0.883, rnaSEQ:0.695, TFs:0.984], roc[ACC:0.799, rnSEQ:0.495, TFs:0.735]\n",
            "05/31 04:38:44 AM | TRAINING: Epoch: 2, Batch: 1550/11962, Loss: 0.116, perc_uncertainty: 0.006, custom[ACC:0.898, rnaSEQ:0.664, TFs:0.977], roc[ACC:0.846, rnSEQ:0.625, TFs:0.757]\n",
            "05/31 04:39:08 AM | TRAINING: Epoch: 2, Batch: 1600/11962, Loss: 0.120, perc_uncertainty: 0.007, custom[ACC:0.867, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.868, rnSEQ:0.559, TFs:0.729]\n",
            "05/31 04:39:31 AM | TRAINING: Epoch: 2, Batch: 1650/11962, Loss: 0.092, perc_uncertainty: 0.007, custom[ACC:0.891, rnaSEQ:0.688, TFs:0.984], roc[ACC:0.844, rnSEQ:0.680, TFs:0.778]\n",
            "05/31 04:39:55 AM | TRAINING: Epoch: 2, Batch: 1700/11962, Loss: 0.114, perc_uncertainty: 0.007, custom[ACC:0.848, rnaSEQ:0.711, TFs:0.980], roc[ACC:0.738, rnSEQ:0.607, TFs:0.756]\n",
            "05/31 04:40:18 AM | TRAINING: Epoch: 2, Batch: 1750/11962, Loss: 0.115, perc_uncertainty: 0.006, custom[ACC:0.871, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.832, rnSEQ:0.605, TFs:0.797]\n",
            "05/31 04:40:42 AM | TRAINING: Epoch: 2, Batch: 1800/11962, Loss: 0.130, perc_uncertainty: 0.007, custom[ACC:0.859, rnaSEQ:0.711, TFs:0.977], roc[ACC:0.853, rnSEQ:0.486, TFs:0.818]\n",
            "05/31 04:41:05 AM | TRAINING: Epoch: 2, Batch: 1850/11962, Loss: 0.117, perc_uncertainty: 0.007, custom[ACC:0.848, rnaSEQ:0.695, TFs:0.977], roc[ACC:0.825, rnSEQ:0.591, TFs:0.766]\n",
            "05/31 04:41:28 AM | TRAINING: Epoch: 2, Batch: 1900/11962, Loss: 0.094, perc_uncertainty: 0.006, custom[ACC:0.879, rnaSEQ:0.711, TFs:0.984], roc[ACC:0.847, rnSEQ:0.532, TFs:0.753]\n",
            "05/31 04:41:52 AM | TRAINING: Epoch: 2, Batch: 1950/11962, Loss: 0.112, perc_uncertainty: 0.006, custom[ACC:0.898, rnaSEQ:0.703, TFs:0.980], roc[ACC:0.821, rnSEQ:0.605, TFs:0.734]\n",
            "05/31 04:42:15 AM | TRAINING: Epoch: 2, Batch: 2000/11962, Loss: 0.122, perc_uncertainty: 0.006, custom[ACC:0.883, rnaSEQ:0.648, TFs:0.977], roc[ACC:0.808, rnSEQ:0.594, TFs:0.790]\n",
            "05/31 04:42:38 AM | TRAINING: Epoch: 2, Batch: 2050/11962, Loss: 0.106, perc_uncertainty: 0.006, custom[ACC:0.840, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.775, rnSEQ:0.532, TFs:0.722]\n",
            "05/31 04:43:02 AM | TRAINING: Epoch: 2, Batch: 2100/11962, Loss: 0.104, perc_uncertainty: 0.006, custom[ACC:0.902, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.801, rnSEQ:0.553, TFs:0.775]\n",
            "05/31 04:43:25 AM | TRAINING: Epoch: 2, Batch: 2150/11962, Loss: 0.112, perc_uncertainty: 0.006, custom[ACC:0.883, rnaSEQ:0.711, TFs:0.980], roc[ACC:0.895, rnSEQ:0.562, TFs:0.779]\n",
            "05/31 04:43:48 AM | TRAINING: Epoch: 2, Batch: 2200/11962, Loss: 0.111, perc_uncertainty: 0.006, custom[ACC:0.867, rnaSEQ:0.625, TFs:0.980], roc[ACC:0.804, rnSEQ:0.541, TFs:0.844]\n",
            "05/31 04:44:12 AM | TRAINING: Epoch: 2, Batch: 2250/11962, Loss: 0.113, perc_uncertainty: 0.005, custom[ACC:0.895, rnaSEQ:0.727, TFs:0.977], roc[ACC:0.839, rnSEQ:0.531, TFs:0.833]\n",
            "05/31 04:44:35 AM | TRAINING: Epoch: 2, Batch: 2300/11962, Loss: 0.124, perc_uncertainty: 0.008, custom[ACC:0.879, rnaSEQ:0.617, TFs:0.969], roc[ACC:0.785, rnSEQ:0.569, TFs:0.801]\n",
            "05/31 04:44:59 AM | TRAINING: Epoch: 2, Batch: 2350/11962, Loss: 0.093, perc_uncertainty: 0.005, custom[ACC:0.871, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.717, rnSEQ:0.588, TFs:0.706]\n",
            "05/31 04:45:22 AM | TRAINING: Epoch: 2, Batch: 2400/11962, Loss: 0.109, perc_uncertainty: 0.006, custom[ACC:0.934, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.902, rnSEQ:0.616, TFs:0.815]\n",
            "05/31 04:45:46 AM | TRAINING: Epoch: 2, Batch: 2450/11962, Loss: 0.117, perc_uncertainty: 0.006, custom[ACC:0.879, rnaSEQ:0.719, TFs:0.984], roc[ACC:0.696, rnSEQ:0.564, TFs:0.643]\n",
            "05/31 04:46:09 AM | TRAINING: Epoch: 2, Batch: 2500/11962, Loss: 0.106, perc_uncertainty: 0.005, custom[ACC:0.922, rnaSEQ:0.688, TFs:0.984], roc[ACC:0.839, rnSEQ:0.555, TFs:0.769]\n",
            "05/31 04:46:33 AM | TRAINING: Epoch: 2, Batch: 2550/11962, Loss: 0.116, perc_uncertainty: 0.006, custom[ACC:0.887, rnaSEQ:0.680, TFs:0.977], roc[ACC:0.740, rnSEQ:0.498, TFs:0.850]\n",
            "05/31 04:46:56 AM | TRAINING: Epoch: 2, Batch: 2600/11962, Loss: 0.098, perc_uncertainty: 0.005, custom[ACC:0.883, rnaSEQ:0.703, TFs:0.984], roc[ACC:0.833, rnSEQ:0.568, TFs:0.632]\n",
            "05/31 04:47:20 AM | TRAINING: Epoch: 2, Batch: 2650/11962, Loss: 0.123, perc_uncertainty: 0.006, custom[ACC:0.863, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.819, rnSEQ:0.664, TFs:0.797]\n",
            "05/31 04:47:43 AM | TRAINING: Epoch: 2, Batch: 2700/11962, Loss: 0.119, perc_uncertainty: 0.005, custom[ACC:0.883, rnaSEQ:0.820, TFs:0.977], roc[ACC:0.738, rnSEQ:0.614, TFs:0.714]\n",
            "05/31 04:48:07 AM | TRAINING: Epoch: 2, Batch: 2750/11962, Loss: 0.119, perc_uncertainty: 0.007, custom[ACC:0.871, rnaSEQ:0.727, TFs:0.977], roc[ACC:0.822, rnSEQ:0.468, TFs:0.808]\n",
            "05/31 04:48:30 AM | TRAINING: Epoch: 2, Batch: 2800/11962, Loss: 0.118, perc_uncertainty: 0.006, custom[ACC:0.859, rnaSEQ:0.688, TFs:0.977], roc[ACC:0.744, rnSEQ:0.558, TFs:0.728]\n",
            "05/31 04:48:53 AM | TRAINING: Epoch: 2, Batch: 2850/11962, Loss: 0.099, perc_uncertainty: 0.005, custom[ACC:0.930, rnaSEQ:0.578, TFs:0.984], roc[ACC:0.892, rnSEQ:0.552, TFs:0.743]\n",
            "05/31 04:49:17 AM | TRAINING: Epoch: 2, Batch: 2900/11962, Loss: 0.116, perc_uncertainty: 0.007, custom[ACC:0.902, rnaSEQ:0.648, TFs:0.977], roc[ACC:0.844, rnSEQ:0.629, TFs:0.788]\n",
            "05/31 04:49:40 AM | TRAINING: Epoch: 2, Batch: 2950/11962, Loss: 0.114, perc_uncertainty: 0.007, custom[ACC:0.875, rnaSEQ:0.703, TFs:0.977], roc[ACC:0.837, rnSEQ:0.639, TFs:0.788]\n",
            "05/31 04:50:04 AM | TRAINING: Epoch: 2, Batch: 3000/11962, Loss: 0.118, perc_uncertainty: 0.007, custom[ACC:0.863, rnaSEQ:0.594, TFs:0.977], roc[ACC:0.786, rnSEQ:0.546, TFs:0.825]\n",
            "05/31 04:50:27 AM | TRAINING: Epoch: 2, Batch: 3050/11962, Loss: 0.120, perc_uncertainty: 0.008, custom[ACC:0.879, rnaSEQ:0.656, TFs:0.969], roc[ACC:0.905, rnSEQ:0.638, TFs:0.857]\n",
            "05/31 04:50:51 AM | TRAINING: Epoch: 2, Batch: 3100/11962, Loss: 0.117, perc_uncertainty: 0.006, custom[ACC:0.879, rnaSEQ:0.664, TFs:0.984], roc[ACC:0.715, rnSEQ:0.505, TFs:0.680]\n",
            "05/31 04:51:14 AM | TRAINING: Epoch: 2, Batch: 3150/11962, Loss: 0.099, perc_uncertainty: 0.007, custom[ACC:0.902, rnaSEQ:0.609, TFs:0.984], roc[ACC:0.857, rnSEQ:0.613, TFs:0.846]\n",
            "05/31 04:51:38 AM | TRAINING: Epoch: 2, Batch: 3200/11962, Loss: 0.089, perc_uncertainty: 0.005, custom[ACC:0.855, rnaSEQ:0.633, TFs:0.992], roc[ACC:0.744, rnSEQ:0.535, TFs:0.733]\n",
            "05/31 04:52:01 AM | TRAINING: Epoch: 2, Batch: 3250/11962, Loss: 0.114, perc_uncertainty: 0.007, custom[ACC:0.871, rnaSEQ:0.648, TFs:0.980], roc[ACC:0.871, rnSEQ:0.578, TFs:0.827]\n",
            "05/31 04:52:24 AM | TRAINING: Epoch: 2, Batch: 3300/11962, Loss: 0.111, perc_uncertainty: 0.006, custom[ACC:0.875, rnaSEQ:0.633, TFs:0.977], roc[ACC:0.800, rnSEQ:0.547, TFs:0.788]\n",
            "05/31 04:52:48 AM | TRAINING: Epoch: 2, Batch: 3350/11962, Loss: 0.113, perc_uncertainty: 0.007, custom[ACC:0.852, rnaSEQ:0.672, TFs:0.977], roc[ACC:0.844, rnSEQ:0.651, TFs:0.794]\n",
            "05/31 04:53:11 AM | TRAINING: Epoch: 2, Batch: 3400/11962, Loss: 0.122, perc_uncertainty: 0.007, custom[ACC:0.855, rnaSEQ:0.648, TFs:0.977], roc[ACC:0.891, rnSEQ:0.551, TFs:0.850]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX-riYdnp9Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-fDOGK2LLNt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}